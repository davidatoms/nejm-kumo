{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab904bdf-4940-4699-8dc3-0f7f5fb52c09",
   "metadata": {},
   "source": [
    "# Brain-to-Text: Preparing Neural Data for Kumo AI\n",
    "\n",
    "This notebook takes the core data processing logic from the BCI phoneme decoding project and packages it for use in Google Colab.\n",
    "\n",
    "The goal is to convert raw neural signals and phoneme annotations into a set of structured tables that are ready to be uploaded to the Kumo AI platform for powerful graph-based analysis.\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1.  **Setup:** Install necessary libraries and define the required Python classes.\n",
    "2.  **Load Data:** Generate a synthetic dataset to demonstrate the pipeline. *(You can replace this step with code to load your own data).*\n",
    "3.  **Process Neural Signals:** Extract key events (peaks and valleys) from the raw time-series data.\n",
    "4.  **Prepare Kumo Tables:** Convert the neural events and phoneme annotations into the relational format Kumo requires.\n",
    "5.  **Save & Download:** Save the final tables as CSV files and download them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1775e-f21b-4845-9dba-015ef57252ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic==2.11.7 kumoai --upgrade --quiet\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import scipy\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import kumoai.experimental.rfm as rfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "477b1254-e7f8-4c44-ad19-d19c7c7fbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class NeuralEvent:\n",
    "#     \"\"\"Represents a neural signal event (peak or valley)\"\"\"\n",
    "#     timestamp: float\n",
    "#     amplitude: float\n",
    "#     channel: int\n",
    "#     event_type: str  # 'peak' or 'valley'\n",
    "#     frequency_band: Optional[str] = None\n",
    "#     duration: Optional[float] = None\n",
    "#     sharpness: Optional[float] = None\n",
    "\n",
    "# @dataclass\n",
    "# class PhonemeEvent:\n",
    "#     \"\"\"Represents a phoneme production event\"\"\"\n",
    "#     phoneme: str\n",
    "#     start_time: float\n",
    "#     end_time: float\n",
    "#     features: Dict[str, Any]\n",
    "\n",
    "# class NeuralSignalProcessor:\n",
    "#     \"\"\"Process raw neural signals to extract peaks and valleys\"\"\"\n",
    "#     def __init__(self, sampling_rate: float = 1000.0, peak_prominence: float = 0.5, min_peak_distance: int = 50):\n",
    "#         self.sampling_rate = sampling_rate\n",
    "#         self.peak_prominence = peak_prominence\n",
    "#         self.min_peak_distance = min_peak_distance\n",
    "\n",
    "#     def extract_peaks_valleys(self, signal_data: np.ndarray) -> Tuple[List[NeuralEvent], List[NeuralEvent]]:\n",
    "#         timestamps = np.arange(signal_data.shape[1]) / self.sampling_rate\n",
    "#         peaks = []\n",
    "#         valleys = []\n",
    "\n",
    "#         for channel_idx, channel_signal in enumerate(signal_data):\n",
    "#             normalized = zscore(channel_signal)\n",
    "#             # Explicitly use scipy.signal.find_peaks\n",
    "#             peak_indices, peak_properties = scipy.signal.find_peaks(\n",
    "#                 normalized, prominence=self.peak_prominence, distance=self.min_peak_distance\n",
    "#             )\n",
    "#             # Explicitly use scipy.signal.find_peaks\n",
    "#             valley_indices, valley_properties = scipy.signal.find_peaks(\n",
    "#                 -normalized, prominence=self.peak_prominence, distance=self.min_peak_distance\n",
    "#             )\n",
    "\n",
    "#             for idx, properties in zip(peak_indices, peak_properties['prominences']):\n",
    "#                 peaks.append(NeuralEvent(\n",
    "#                     timestamp=timestamps[idx],\n",
    "#                     amplitude=channel_signal[idx],\n",
    "#                     channel=channel_idx,\n",
    "#                     event_type='peak',\n",
    "#                     sharpness=properties\n",
    "#                 ))\n",
    "\n",
    "#             for idx, properties in zip(valley_indices, valley_properties['prominences']):\n",
    "#                 valleys.append(NeuralEvent(\n",
    "#                     timestamp=timestamps[idx],\n",
    "#                     amplitude=channel_signal[idx],\n",
    "#                     channel=channel_idx,\n",
    "#                     event_type='valley',\n",
    "#                     sharpness=properties\n",
    "#                 ))\n",
    "#         return peaks, valleys\n",
    "\n",
    "# class KumoNeuralPhonemeIntegration:\n",
    "#     \"\"\"Integration layer for preparing data for Kumo AI\"\"\"\n",
    "#     def prepare_for_kumo(self, neural_data: pd.DataFrame, phoneme_data: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "#         # Create event tables\n",
    "#         neural_events_table = pd.DataFrame({\n",
    "#             'event_id': range(len(neural_data)),\n",
    "#             'timestamp': neural_data['timestamp'],\n",
    "#             'amplitude': neural_data['amplitude'],\n",
    "#             'channel': neural_data['channel'],\n",
    "#             'event_type': neural_data['event_type'],\n",
    "#             'subject_id': neural_data.get('subject_id', 'default')\n",
    "#         })\n",
    "\n",
    "#         phoneme_events_table = pd.DataFrame({\n",
    "#             'phoneme_id': range(len(phoneme_data)),\n",
    "#             'phoneme': phoneme_data['phoneme'],\n",
    "#             'start_time': phoneme_data['start_time'],\n",
    "#             'end_time': phoneme_data['end_time'],\n",
    "#             'subject_id': phoneme_data.get('subject_id', 'default')\n",
    "#         })\n",
    "\n",
    "#         # Create relationship table for potential causal connections\n",
    "#         causal_relationships = []\n",
    "#         for _, neural_row in neural_events_table.iterrows():\n",
    "#             for _, phoneme_row in phoneme_events_table.iterrows():\n",
    "#                 delay = phoneme_row['start_time'] - neural_row['timestamp']\n",
    "#                 if 0.05 <= delay <= 0.5:  # Potential causal window\n",
    "#                     causal_relationships.append({\n",
    "#                         'neural_event_id': neural_row['event_id'],\n",
    "#                         'phoneme_id': phoneme_row['phoneme_id'],\n",
    "#                         'delay': delay\n",
    "#                     })\n",
    "\n",
    "#         causality_table = pd.DataFrame(causal_relationships)\n",
    "\n",
    "#         return {\n",
    "#             'neural_events': neural_events_table,\n",
    "#             'phoneme_events': phoneme_events_table,\n",
    "#             'causal_relationships': causality_table\n",
    "#         }\n",
    "\n",
    "# print(\"Setup complete. All classes are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62ef98a-d1cd-4037-b656-735e381edd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose download method:\n",
      "1. Full version with progress bars (recommended)\n",
      "2. Simple version (if rate limiting issues persist)\n",
      "Data will be downloaded to: /home/ubuntu/data\n",
      "Fetching file list from Dryad...\n",
      "Found 5 files to download.\n",
      "Skipping README.md\n",
      "\n",
      "[2/5] Processing: t15_copyTask_neuralData.zip\n",
      "File already exists (980.3 MB). Skipping download.\n",
      "Extracting files from t15_copyTask_neuralData.zip...\n",
      "‚úó Error extracting t15_copyTask_neuralData.zip: File is not a zip file\n",
      "\n",
      "[3/5] Processing: t15_copyTask.pkl\n",
      "File already exists (57.8 MB). Skipping download.\n",
      "\n",
      "[4/5] Processing: t15_personalUse.pkl\n",
      "File already exists (1.1 MB). Skipping download.\n",
      "\n",
      "[5/5] Processing: t15_pretrained_rnn_baseline.zip\n",
      "File already exists (484.9 MB). Skipping download.\n",
      "Extracting files from t15_pretrained_rnn_baseline.zip...\n",
      "  Extracting 12 files...\n",
      "  Extracted 12/12 files...\n",
      "‚úì Extraction complete: 12 files\n",
      "\n",
      "üéâ Download complete! See data files in /home/ubuntu/data\n",
      "\n",
      "Downloaded files (6 total):\n",
      "  üìÅ __MACOSX/\n",
      "  üìÑ t15_copyTask.pkl (57.8 MB)\n",
      "  üìÑ t15_copyTask_neuralData.zip (980.3 MB)\n",
      "  üìÑ t15_personalUse.pkl (1.1 MB)\n",
      "  üìÅ t15_pretrained_rnn_baseline/\n",
      "  üìÑ t15_pretrained_rnn_baseline.zip (484.9 MB)\n"
     ]
    }
   ],
   "source": [
    "# # @title Step 2: Download Real Data from Dryad (Rate Limited)\n",
    "# # This cell contains the logic from the `download_data.py` script, adapted\n",
    "# # for Colab/Jupyter with proper rate limiting to avoid IOPub message overflow\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# import urllib.request\n",
    "# import json\n",
    "# import zipfile\n",
    "# import time\n",
    "# from threading import Lock\n",
    "\n",
    "# # Global variables for rate limiting\n",
    "# _last_update_time = {}\n",
    "# _update_lock = Lock()\n",
    "\n",
    "# def display_progress_bar(block_num, block_size, total_size, message=\"\", filename=\"\"):\n",
    "#     \"\"\"Helper function to show a download progress bar with rate limiting.\"\"\"\n",
    "#     bytes_downloaded_so_far = block_num * block_size\n",
    "#     MB_downloaded_so_far = bytes_downloaded_so_far / 1e6\n",
    "#     MB_total = total_size / 1e6\n",
    "#     current_time = time.time()\n",
    "    \n",
    "#     # Use filename as key for tracking updates per file\n",
    "#     file_key = filename or \"default\"\n",
    "    \n",
    "#     with _update_lock:\n",
    "#         # Only update every 2 seconds to avoid rate limiting\n",
    "#         if (file_key not in _last_update_time or \n",
    "#             (current_time - _last_update_time[file_key]) > 2.0):\n",
    "            \n",
    "#             # Calculate percentage and speed\n",
    "#             percentage = (bytes_downloaded_so_far / total_size * 100) if total_size > 0 else 0\n",
    "            \n",
    "#             # Show progress with less frequent updates\n",
    "#             sys.stdout.write(\n",
    "#                 f\"\\r{message}: {MB_downloaded_so_far:.1f}/{MB_total:.1f} MB ({percentage:.1f}%)\"\n",
    "#             )\n",
    "#             sys.stdout.flush()\n",
    "            \n",
    "#             _last_update_time[file_key] = current_time\n",
    "\n",
    "# def download_with_progress(url, filepath, filename):\n",
    "#     \"\"\"Download a file with rate-limited progress reporting.\"\"\"\n",
    "#     print(f\"\\nStarting download: {filename}\")\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     def progress_hook(block_num, block_size, total_size):\n",
    "#         display_progress_bar(block_num, block_size, total_size, \n",
    "#                            f\"Downloading {filename}\", filename)\n",
    "    \n",
    "#     try:\n",
    "#         urllib.request.urlretrieve(url, filepath, reporthook=progress_hook)\n",
    "        \n",
    "#         # Final status\n",
    "#         file_size = os.path.getsize(filepath) / 1e6 if os.path.exists(filepath) else 0\n",
    "#         duration = time.time() - start_time\n",
    "#         speed = file_size / duration if duration > 0 else 0\n",
    "        \n",
    "#         print(f\"\\n‚úì {filename} complete: {file_size:.1f} MB in {duration:.1f}s ({speed:.1f} MB/s)\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n‚úó Error downloading {filename}: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def download_and_unzip_data():\n",
    "#     \"\"\"Downloads and unzips the BCI competition data from Dryad with rate limiting.\"\"\"\n",
    "#     DRYAD_DOI = \"10.5061/dryad.dncjsxm85\"\n",
    "#     DATA_DIR = \"data/\"\n",
    "    \n",
    "#     # Create the data directory\n",
    "#     os.makedirs(DATA_DIR, exist_ok=True)\n",
    "#     data_dirpath = os.path.abspath(DATA_DIR)\n",
    "#     print(f\"Data will be downloaded to: {data_dirpath}\")\n",
    "    \n",
    "#     # Add delay to avoid hitting API limits\n",
    "#     time.sleep(1)\n",
    "    \n",
    "#     # Get the list of files from the latest version on Dryad\n",
    "#     DRYAD_ROOT = \"https://datadryad.org\"\n",
    "#     urlified_doi = DRYAD_DOI.replace(\"/\", \"%2F\")\n",
    "#     versions_url = f\"{DRYAD_ROOT}/api/v2/datasets/doi:{urlified_doi}/versions\"\n",
    "    \n",
    "#     print(\"Fetching file list from Dryad...\")\n",
    "#     try:\n",
    "#         with urllib.request.urlopen(versions_url) as response:\n",
    "#             versions_info = json.loads(response.read().decode())\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching version info: {e}\")\n",
    "#         return\n",
    "    \n",
    "#     time.sleep(1)  # Rate limit API calls\n",
    "    \n",
    "#     files_url_path = versions_info[\"_embedded\"][\"stash:versions\"][-1][\"_links\"][\"stash:files\"][\"href\"]\n",
    "#     files_url = f\"{DRYAD_ROOT}{files_url_path}\"\n",
    "    \n",
    "#     try:\n",
    "#         with urllib.request.urlopen(files_url) as response:\n",
    "#             files_info = json.loads(response.read().decode())\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching file info: {e}\")\n",
    "#         return\n",
    "    \n",
    "#     file_infos = files_info[\"_embedded\"][\"stash:files\"]\n",
    "#     print(f\"Found {len(file_infos)} files to download.\")\n",
    "    \n",
    "#     # Download each file into the data directory\n",
    "#     for i, file_info in enumerate(file_infos, 1):\n",
    "#         filename = file_info[\"path\"]\n",
    "        \n",
    "#         if filename == \"README.md\":\n",
    "#             print(f\"Skipping {filename}\")\n",
    "#             continue\n",
    "        \n",
    "#         print(f\"\\n[{i}/{len(file_infos)}] Processing: {filename}\")\n",
    "        \n",
    "#         download_path = file_info[\"_links\"][\"stash:download\"][\"href\"]\n",
    "#         download_url = f\"{DRYAD_ROOT}{download_path}\"\n",
    "#         download_to_filepath = os.path.join(data_dirpath, filename)\n",
    "        \n",
    "#         # Check if file already exists\n",
    "#         if os.path.exists(download_to_filepath):\n",
    "#             file_size = os.path.getsize(download_to_filepath) / 1e6\n",
    "#             print(f\"File already exists ({file_size:.1f} MB). Skipping download.\")\n",
    "#         else:\n",
    "#             # Download the file with progress\n",
    "#             download_with_progress(download_url, download_to_filepath, filename)\n",
    "        \n",
    "#         # If this file is a zip file, unzip it\n",
    "#         if file_info[\"mimeType\"] == \"application/zip\":\n",
    "#             print(f\"Extracting files from {filename}...\")\n",
    "#             try:\n",
    "#                 with zipfile.ZipFile(download_to_filepath, \"r\") as zf:\n",
    "#                     # Get extraction info\n",
    "#                     file_list = zf.namelist()\n",
    "#                     print(f\"  Extracting {len(file_list)} files...\")\n",
    "                    \n",
    "#                     # Extract with progress for large archives\n",
    "#                     extracted_count = 0\n",
    "#                     for member in file_list:\n",
    "#                         zf.extract(member, data_dirpath)\n",
    "#                         extracted_count += 1\n",
    "                        \n",
    "#                         # Rate-limited extraction progress\n",
    "#                         if extracted_count % 100 == 0 or extracted_count == len(file_list):\n",
    "#                             print(f\"  Extracted {extracted_count}/{len(file_list)} files...\")\n",
    "                \n",
    "#                 print(f\"‚úì Extraction complete: {len(file_list)} files\")\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"‚úó Error extracting {filename}: {e}\")\n",
    "        \n",
    "#         # Rate limit between files\n",
    "#         time.sleep(0.5)\n",
    "    \n",
    "#     print(f\"\\nüéâ Download complete! See data files in {data_dirpath}\")\n",
    "    \n",
    "#     # Show final directory contents\n",
    "#     try:\n",
    "#         files = os.listdir(data_dirpath)\n",
    "#         print(f\"\\nDownloaded files ({len(files)} total):\")\n",
    "#         for file in sorted(files)[:10]:  # Show first 10 files\n",
    "#             file_path = os.path.join(data_dirpath, file)\n",
    "#             if os.path.isfile(file_path):\n",
    "#                 size_mb = os.path.getsize(file_path) / 1e6\n",
    "#                 print(f\"  üìÑ {file} ({size_mb:.1f} MB)\")\n",
    "#             else:\n",
    "#                 print(f\"  üìÅ {file}/\")\n",
    "        \n",
    "#         if len(files) > 10:\n",
    "#             print(f\"  ... and {len(files) - 10} more files\")\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error listing directory: {e}\")\n",
    "\n",
    "# # Alternative: Simplified version for very restrictive environments\n",
    "# def download_simple():\n",
    "#     \"\"\"Simplified download with minimal output for restrictive Jupyter environments.\"\"\"\n",
    "#     DRYAD_DOI = \"10.5061/dryad.dncjsxm85\"\n",
    "#     DATA_DIR = \"data/\"\n",
    "    \n",
    "#     os.makedirs(DATA_DIR, exist_ok=True)\n",
    "#     data_dirpath = os.path.abspath(DATA_DIR)\n",
    "    \n",
    "#     print(\"Starting Dryad download (simplified mode)...\")\n",
    "    \n",
    "#     # Get file list\n",
    "#     DRYAD_ROOT = \"https://datadryad.org\"\n",
    "#     urlified_doi = DRYAD_DOI.replace(\"/\", \"%2F\")\n",
    "#     versions_url = f\"{DRYAD_ROOT}/api/v2/datasets/doi:{urlified_doi}/versions\"\n",
    "    \n",
    "#     with urllib.request.urlopen(versions_url) as response:\n",
    "#         versions_info = json.loads(response.read().decode())\n",
    "    \n",
    "#     files_url_path = versions_info[\"_embedded\"][\"stash:versions\"][-1][\"_links\"][\"stash:files\"][\"href\"]\n",
    "#     files_url = f\"{DRYAD_ROOT}{files_url_path}\"\n",
    "    \n",
    "#     with urllib.request.urlopen(files_url) as response:\n",
    "#         files_info = json.loads(response.read().decode())\n",
    "    \n",
    "#     file_infos = files_info[\"_embedded\"][\"stash:files\"]\n",
    "    \n",
    "#     # Download files with minimal output\n",
    "#     for file_info in file_infos:\n",
    "#         filename = file_info[\"path\"]\n",
    "#         if filename == \"README.md\":\n",
    "#             continue\n",
    "            \n",
    "#         download_path = file_info[\"_links\"][\"stash:download\"][\"href\"]\n",
    "#         download_url = f\"{DRYAD_ROOT}{download_path}\"\n",
    "#         download_to_filepath = os.path.join(data_dirpath, filename)\n",
    "        \n",
    "#         print(f\"Downloading {filename}...\")\n",
    "#         urllib.request.urlretrieve(download_url, download_to_filepath)\n",
    "        \n",
    "#         if file_info[\"mimeType\"] == \"application/zip\":\n",
    "#             print(f\"Extracting {filename}...\")\n",
    "#             with zipfile.ZipFile(download_to_filepath, \"r\") as zf:\n",
    "#                 zf.extractall(data_dirpath)\n",
    "    \n",
    "#     print(\"Download complete!\")\n",
    "\n",
    "# # Run the download function\n",
    "# print(\"Choose download method:\")\n",
    "# print(\"1. Full version with progress bars (recommended)\")\n",
    "# print(\"2. Simple version (if rate limiting issues persist)\")\n",
    "\n",
    "# # Uncomment the version you want to use:\n",
    "# download_and_unzip_data()  # Full version\n",
    "# # download_simple()  # Simple version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520ec30c-5917-418f-b337-1f6f811bda42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying to load pickle file: data/t15_copyTask.pkl\n",
      "Successfully loaded!\n",
      "Data type: <class 'dict'>\n",
      "Dictionary keys: ['post_implant_day', 'vocab_size', 'cue_sentence', 'cue_sentence_phonemes', 'decoded_logits', 'decoded_phonemes_raw', 'decoded_sentence', 'decoded_sentence_phonemes', 'speech_duration_s']\n"
     ]
    }
   ],
   "source": [
    "# @title Load data from alternative formats\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Option 1: Try pickle files\n",
    "pkl_files = [\"data/t15_copyTask.pkl\", \"data/personalUse.pkl\"]\n",
    "\n",
    "for pkl_file in pkl_files:\n",
    "    if os.path.exists(pkl_file):\n",
    "        print(f\"\\nTrying to load pickle file: {pkl_file}\")\n",
    "        try:\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                print(f\"Successfully loaded!\")\n",
    "                print(f\"Data type: {type(data)}\")\n",
    "\n",
    "                if isinstance(data, dict):\n",
    "                    print(f\"Dictionary keys: {list(data.keys())}\")\n",
    "                    # Check for neural data\n",
    "                    for key in data.keys():\n",
    "                        if 'neural' in key.lower() or 'signal' in key.lower():\n",
    "                            print(f\"  Found potential neural data in key: {key}\")\n",
    "                            print(f\"  Shape: {data[key].shape if hasattr(data[key], 'shape') else 'N/A'}\")\n",
    "\n",
    "                # Store for processing\n",
    "                loaded_data = data\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {pkl_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bfbb43-3128-4774-a1d6-f542273c3c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API key loaded from kumo_config.py\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Import from your config file\n",
    "    from kumo_config import KUMO_API_KEY\n",
    "    os.environ[\"KUMO_API_KEY\"] = KUMO_API_KEY\n",
    "    print(\"‚úì API key loaded from kumo_config.py\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  kumo_config.py not found, will use interactive authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be39838-0c04-4b8d-9e9e-947a29ed6e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from pickle file...\n",
      "Decoded logits is a list of 1718 arrays.\n",
      "Concatenated decoded logits shape: (346439, 41)\n",
      "Neural signals shape: (41, 346439) (channels √ó time points)\n",
      "Estimated sampling rate: 84087.1 Hz\n",
      "\n",
      "Created 46276 phoneme annotations across 1718 trials.\n",
      "Vocabulary size: 50 words (based on the first trial)\n"
     ]
    }
   ],
   "source": [
    "# Extract Neural Signals and Phoneme Data from Pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Extract the decoded logits as neural signals\n",
    "print(\"Extracting data from pickle file...\")\n",
    "\n",
    "# Use decoded_logits as neural signal representation\n",
    "decoded_logits_list = loaded_data['decoded_logits']\n",
    "print(f\"Decoded logits is a list of {len(decoded_logits_list)} arrays.\")\n",
    "\n",
    "# Concatenate the list of arrays into a single NumPy array\n",
    "if decoded_logits_list:\n",
    "    decoded_logits = np.concatenate(decoded_logits_list, axis=0)\n",
    "    print(f\"Concatenated decoded logits shape: {decoded_logits.shape}\")\n",
    "\n",
    "    # Convert to neural signals format (channels √ó time)\n",
    "    # Assuming channels are the second dimension after concatenation, time is the first\n",
    "    neural_signals = decoded_logits.T\n",
    "    print(f\"Neural signals shape: {neural_signals.shape} (channels √ó time points)\")\n",
    "\n",
    "    # Set sampling rate b KI ased on phoneme rate (assuming decoded_logits time points align with phoneme duration)\n",
    "    # This might need adjustment based on actual data structure and timing\n",
    "    SAMPLING_RATE = decoded_logits.shape[0] / loaded_data['speech_duration_s'][0] # Assuming speech_duration_s is a list\n",
    "    print(f\"Estimated sampling rate: {SAMPLING_RATE:.1f} Hz\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: decoded_logits list is empty.\")\n",
    "    neural_signals = np.array([]) # Initialize as empty array to prevent further errors\n",
    "    SAMPLING_RATE = 1000.0 # Default or handle appropriately\n",
    "\n",
    "\n",
    "# Create phoneme annotations\n",
    "phonemes = loaded_data['cue_sentence_phonemes']\n",
    "duration = loaded_data['speech_duration_s']\n",
    "n_trials = len(phonemes) # Number of trials is the number of sentences/phoneme lists\n",
    "\n",
    "all_phoneme_annotations = []\n",
    "\n",
    "# Iterate through each trial to create phoneme annotations\n",
    "for trial_idx in range(n_trials):\n",
    "    trial_phonemes = phonemes[trial_idx]\n",
    "    trial_duration = duration[trial_idx]\n",
    "    n_phonemes_in_trial = len(trial_phonemes)\n",
    "\n",
    "    if n_phonemes_in_trial > 0:\n",
    "      # Create start and end times for phonemes in this trial\n",
    "      # Distribute phonemes evenly across the trial duration\n",
    "      start_times = np.linspace(0, trial_duration * 0.9, n_phonemes_in_trial)\n",
    "      end_times = np.linspace(trial_duration * 0.1, trial_duration, n_phonemes_in_trial)\n",
    "\n",
    "      trial_annotations = pd.DataFrame({\n",
    "          'trial_id': loaded_data['post_implant_day'][trial_idx],\n",
    "          'phoneme_id': [f'{trial_idx}_{i}' for i in range(n_phonemes_in_trial)], # Unique ID per phoneme\n",
    "          'phoneme': trial_phonemes,\n",
    "          'start_time': start_times,\n",
    "          'end_time': end_times,\n",
    "          'duration': end_times - start_times,\n",
    "          'sequence_position': range(n_phonemes_in_trial),\n",
    "          'total_sequence_length': n_phonemes_in_trial,\n",
    "          'subject_id': 't15' # Assuming subject id is constant for this dataset\n",
    "      })\n",
    "      all_phoneme_annotations.append(trial_annotations)\n",
    "\n",
    "# Concatenate all trial annotations into a single DataFrame\n",
    "if all_phoneme_annotations:\n",
    "  phoneme_annotations = pd.concat(all_phoneme_annotations, ignore_index=True)\n",
    "else:\n",
    "  phoneme_annotations = pd.DataFrame() # Empty DataFrame if no phonemes found\n",
    "\n",
    "print(f\"\\nCreated {len(phoneme_annotations)} phoneme annotations across {n_trials} trials.\")\n",
    "# print(f\"Trial: Day {loaded_data['post_implant_day']} post-implant\") # This will print a list, which is not very informative\n",
    "print(f\"Vocabulary size: {loaded_data['vocab_size'][0]} words (based on the first trial)\") # Assuming vocab size is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508282e1-c6a7-4eb1-a082-780d581bb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing neural signals into discrete events...\n",
      "Input validation:\n",
      "  Neural signals shape: (41, 346439)\n",
      "  Sampling rate: 84087.1359223301 Hz\n",
      "  Channels to process: 41\n",
      "Peak detection parameters:\n",
      "  Prominence threshold: 0.5\n",
      "  Minimum distance: 10ms (840 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing channels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:01<00:00, 33.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Neural event extraction completed!\n",
      "üìä Summary statistics:\n",
      "  Channels processed: 41\n",
      "  Channels skipped: 0\n",
      "  Total events extracted: 25123\n",
      "  Peaks: 12594\n",
      "  Valleys: 12529\n",
      "  Time range: 0.000s - 4.120s\n",
      "  Average events per channel: 612.8\n",
      "  Most active channel: 17 (630 events)\n",
      "  Least active channel: 3 (599 events)\n",
      "üìà Amplitude statistics:\n",
      "  Peak amplitudes: count    12594.000000\n",
      "mean        23.822777\n",
      "std          9.594965\n",
      "min        -10.531623\n",
      "25%         16.162013\n",
      "50%         26.001776\n",
      "75%         30.278698\n",
      "max         60.857002\n",
      "Name: amplitude, dtype: float64\n",
      "  Valley amplitudes: count    12529.000000\n",
      "mean       -14.346450\n",
      "std          3.787599\n",
      "min        -30.202309\n",
      "25%        -16.828918\n",
      "50%        -14.386750\n",
      "75%        -12.071593\n",
      "max         17.986731\n",
      "Name: amplitude, dtype: float64\n",
      "\n",
      "üéØ Neural event extraction complete and ready for causal analysis!\n"
     ]
    }
   ],
   "source": [
    "# @title: Extract Peaks and Valleys from Neural Signals (Enhanced)\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "print(\"Processing neural signals into discrete events...\")\n",
    "\n",
    "# Validate inputs first\n",
    "if 'neural_signals' not in locals():\n",
    "    print(\"‚ùå Error: neural_signals not found\")\n",
    "    raise ValueError(\"neural_signals must be defined first\")\n",
    "\n",
    "if 'SAMPLING_RATE' not in locals():\n",
    "    print(\"‚ö†Ô∏è Warning: SAMPLING_RATE not defined, using default 1000.0 Hz\")\n",
    "    SAMPLING_RATE = 1000.0\n",
    "\n",
    "if 'loaded_data' not in locals():\n",
    "    print(\"‚ö†Ô∏è Warning: loaded_data not found, using default trial_id\")\n",
    "    loaded_data = {'post_implant_day': ['default_trial']}\n",
    "\n",
    "print(f\"Input validation:\")\n",
    "print(f\"  Neural signals shape: {neural_signals.shape}\")\n",
    "print(f\"  Sampling rate: {SAMPLING_RATE} Hz\")\n",
    "print(f\"  Channels to process: {neural_signals.shape[0]}\")\n",
    "\n",
    "# Initialize lists for events\n",
    "neural_events = []\n",
    "event_id = 0\n",
    "channels_processed = 0\n",
    "channels_skipped = 0\n",
    "\n",
    "# Parameters for peak detection (make these configurable)\n",
    "PEAK_PROMINENCE = 0.5\n",
    "MIN_DISTANCE_MS = 10  # Minimum 10ms between peaks\n",
    "MIN_DISTANCE_SAMPLES = int(SAMPLING_RATE * (MIN_DISTANCE_MS / 1000))\n",
    "\n",
    "print(f\"Peak detection parameters:\")\n",
    "print(f\"  Prominence threshold: {PEAK_PROMINENCE}\")\n",
    "print(f\"  Minimum distance: {MIN_DISTANCE_MS}ms ({MIN_DISTANCE_SAMPLES} samples)\")\n",
    "\n",
    "# Process each channel with progress bar\n",
    "for channel_idx in tqdm(range(neural_signals.shape[0]), desc=\"Processing channels\"):\n",
    "    channel_signal = neural_signals[channel_idx, :]\n",
    "    \n",
    "    # Skip if channel is flat or has invalid data\n",
    "    signal_std = np.std(channel_signal)\n",
    "    if signal_std < 1e-6:\n",
    "        channels_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Check for NaN or infinite values\n",
    "    if np.any(np.isnan(channel_signal)) or np.any(np.isinf(channel_signal)):\n",
    "        print(f\"‚ö†Ô∏è Warning: Channel {channel_idx} contains NaN/inf values, skipping\")\n",
    "        channels_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Normalize the signal\n",
    "    try:\n",
    "        normalized = zscore(channel_signal)\n",
    "        \n",
    "        # Handle case where zscore returns NaN (constant signal)\n",
    "        if np.any(np.isnan(normalized)):\n",
    "            print(f\"‚ö†Ô∏è Warning: Channel {channel_idx} normalization failed, skipping\")\n",
    "            channels_skipped += 1\n",
    "            continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Channel {channel_idx} normalization error: {e}\")\n",
    "        channels_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Find peaks with error handling\n",
    "    try:\n",
    "        peak_indices, peak_properties = find_peaks(\n",
    "            normalized,\n",
    "            prominence=PEAK_PROMINENCE,\n",
    "            distance=MIN_DISTANCE_SAMPLES\n",
    "        )\n",
    "        \n",
    "        # Find valleys (peaks in inverted signal)\n",
    "        valley_indices, valley_properties = find_peaks(\n",
    "            -normalized,\n",
    "            prominence=PEAK_PROMINENCE,\n",
    "            distance=MIN_DISTANCE_SAMPLES\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Peak detection failed for channel {channel_idx}: {e}\")\n",
    "        channels_skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Handle trial_id properly (it might be a list)\n",
    "    trial_id_value = loaded_data['post_implant_day']\n",
    "    if isinstance(trial_id_value, list):\n",
    "        trial_id_value = trial_id_value[0] if trial_id_value else 'unknown'\n",
    "    \n",
    "    # Create events for peaks\n",
    "    for i, idx in enumerate(peak_indices):\n",
    "        # Add additional peak properties if available\n",
    "        prominence = peak_properties.get('prominences', [0])[i] if 'prominences' in peak_properties else 0\n",
    "        \n",
    "        neural_events.append({\n",
    "            'event_id': event_id,\n",
    "            'timestamp': idx / SAMPLING_RATE,\n",
    "            'amplitude': channel_signal[idx],\n",
    "            'normalized_amplitude': normalized[idx],\n",
    "            'prominence': prominence,\n",
    "            'channel': channel_idx,\n",
    "            'event_type': 'peak',\n",
    "            'channel_region': channel_idx // 8,  # Group into regions\n",
    "            'trial_id': trial_id_value,\n",
    "            'sample_index': idx\n",
    "        })\n",
    "        event_id += 1\n",
    "    \n",
    "    # Create events for valleys\n",
    "    for i, idx in enumerate(valley_indices):\n",
    "        # Add additional valley properties if available\n",
    "        prominence = valley_properties.get('prominences', [0])[i] if 'prominences' in valley_properties else 0\n",
    "        \n",
    "        neural_events.append({\n",
    "            'event_id': event_id,\n",
    "            'timestamp': idx / SAMPLING_RATE,\n",
    "            'amplitude': channel_signal[idx],\n",
    "            'normalized_amplitude': -normalized[idx],  # Negative because we inverted for valley detection\n",
    "            'prominence': prominence,\n",
    "            'channel': channel_idx,\n",
    "            'event_type': 'valley',\n",
    "            'channel_region': channel_idx // 8,\n",
    "            'trial_id': trial_id_value,\n",
    "            'sample_index': idx\n",
    "        })\n",
    "        event_id += 1\n",
    "    \n",
    "    channels_processed += 1\n",
    "\n",
    "# Create DataFrame and sort by timestamp\n",
    "if neural_events:\n",
    "    neural_events_df = pd.DataFrame(neural_events).sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\n‚úÖ Neural event extraction completed!\")\n",
    "    print(f\"üìä Summary statistics:\")\n",
    "    print(f\"  Channels processed: {channels_processed}\")\n",
    "    print(f\"  Channels skipped: {channels_skipped}\")\n",
    "    print(f\"  Total events extracted: {len(neural_events_df)}\")\n",
    "    print(f\"  Peaks: {sum(neural_events_df['event_type'] == 'peak')}\")\n",
    "    print(f\"  Valleys: {sum(neural_events_df['event_type'] == 'valley')}\")\n",
    "    print(f\"  Time range: {neural_events_df['timestamp'].min():.3f}s - {neural_events_df['timestamp'].max():.3f}s\")\n",
    "    print(f\"  Average events per channel: {len(neural_events_df) / channels_processed:.1f}\")\n",
    "    \n",
    "    # Channel-wise analysis\n",
    "    events_per_channel = neural_events_df.groupby('channel').size()\n",
    "    print(f\"  Most active channel: {events_per_channel.idxmax()} ({events_per_channel.max()} events)\")\n",
    "    print(f\"  Least active channel: {events_per_channel.idxmin()} ({events_per_channel.min()} events)\")\n",
    "    \n",
    "    # Amplitude analysis\n",
    "    print(f\"üìà Amplitude statistics:\")\n",
    "    print(f\"  Peak amplitudes: {neural_events_df[neural_events_df['event_type'] == 'peak']['amplitude'].describe()}\")\n",
    "    print(f\"  Valley amplitudes: {neural_events_df[neural_events_df['event_type'] == 'valley']['amplitude'].describe()}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No neural events extracted! Check your signal processing parameters.\")\n",
    "    neural_events_df = pd.DataFrame()\n",
    "\n",
    "# --- ADVANCED VERSION WITH ADAPTIVE PARAMETERS ---\n",
    "def extract_neural_events_adaptive(neural_signals, sampling_rate, \n",
    "                                 adaptive_prominence=True,\n",
    "                                 min_events_per_channel=10,\n",
    "                                 max_events_per_channel=1000):\n",
    "    \"\"\"\n",
    "    Enhanced version with adaptive parameters for different channel characteristics\n",
    "    \"\"\"\n",
    "    print(\"üß† Adaptive neural event extraction...\")\n",
    "    \n",
    "    all_events = []\n",
    "    event_id = 0\n",
    "    \n",
    "    for channel_idx in tqdm(range(neural_signals.shape[0]), desc=\"Adaptive processing\"):\n",
    "        channel_signal = neural_signals[channel_idx, :]\n",
    "        \n",
    "        if np.std(channel_signal) < 1e-6:\n",
    "            continue\n",
    "        \n",
    "        normalized = zscore(channel_signal)\n",
    "        \n",
    "        # Adaptive prominence based on signal characteristics\n",
    "        if adaptive_prominence:\n",
    "            signal_variance = np.var(normalized)\n",
    "            prominence = max(0.3, min(1.0, signal_variance * 0.5))\n",
    "        else:\n",
    "            prominence = 0.5\n",
    "        \n",
    "        # Try different distance parameters if not enough events\n",
    "        distances = [int(sampling_rate * 0.005), int(sampling_rate * 0.01), int(sampling_rate * 0.02)]\n",
    "        \n",
    "        for distance in distances:\n",
    "            peak_indices, _ = find_peaks(normalized, prominence=prominence, distance=distance)\n",
    "            valley_indices, _ = find_peaks(-normalized, prominence=prominence, distance=distance)\n",
    "            \n",
    "            total_events = len(peak_indices) + len(valley_indices)\n",
    "            \n",
    "            if min_events_per_channel <= total_events <= max_events_per_channel:\n",
    "                break\n",
    "        \n",
    "        # Create events with adaptive parameters\n",
    "        for idx in peak_indices:\n",
    "            all_events.append({\n",
    "                'event_id': event_id,\n",
    "                'timestamp': idx / sampling_rate,\n",
    "                'amplitude': channel_signal[idx],\n",
    "                'channel': channel_idx,\n",
    "                'event_type': 'peak',\n",
    "                'prominence_used': prominence,\n",
    "                'distance_used': distance\n",
    "            })\n",
    "            event_id += 1\n",
    "        \n",
    "        for idx in valley_indices:\n",
    "            all_events.append({\n",
    "                'event_id': event_id,\n",
    "                'timestamp': idx / sampling_rate,\n",
    "                'amplitude': channel_signal[idx],\n",
    "                'channel': channel_idx,\n",
    "                'event_type': 'valley',\n",
    "                'prominence_used': prominence,\n",
    "                'distance_used': distance\n",
    "            })\n",
    "            event_id += 1\n",
    "    \n",
    "    return pd.DataFrame(all_events).sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# --- QUALITY CONTROL VERSION ---\n",
    "def extract_neural_events_with_qc(neural_signals, sampling_rate,\n",
    "                                signal_quality_threshold=0.1,\n",
    "                                artifact_threshold=5.0):\n",
    "    \"\"\"\n",
    "    Version with signal quality control and artifact rejection\n",
    "    \"\"\"\n",
    "    print(\"üîç Neural event extraction with quality control...\")\n",
    "    \n",
    "    events = []\n",
    "    event_id = 0\n",
    "    qc_stats = {'good_channels': 0, 'noisy_channels': 0, 'flat_channels': 0}\n",
    "    \n",
    "    for channel_idx in tqdm(range(neural_signals.shape[0]), desc=\"QC processing\"):\n",
    "        channel_signal = neural_signals[channel_idx, :]\n",
    "        \n",
    "        # Signal quality assessment\n",
    "        signal_std = np.std(channel_signal)\n",
    "        signal_range = np.ptp(channel_signal)  # Peak-to-peak\n",
    "        \n",
    "        # Skip flat channels\n",
    "        if signal_std < 1e-6:\n",
    "            qc_stats['flat_channels'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Skip very noisy channels\n",
    "        normalized = zscore(channel_signal)\n",
    "        if np.any(np.abs(normalized) > artifact_threshold):\n",
    "            qc_stats['noisy_channels'] += 1\n",
    "            continue\n",
    "        \n",
    "        qc_stats['good_channels'] += 1\n",
    "        \n",
    "        # Proceed with peak detection\n",
    "        peak_indices, peak_props = find_peaks(\n",
    "            normalized, \n",
    "            prominence=0.5, \n",
    "            distance=int(sampling_rate * 0.01)\n",
    "        )\n",
    "        \n",
    "        valley_indices, valley_props = find_peaks(\n",
    "            -normalized, \n",
    "            prominence=0.5, \n",
    "            distance=int(sampling_rate * 0.01)\n",
    "        )\n",
    "        \n",
    "        # Add quality metrics to events\n",
    "        for i, idx in enumerate(peak_indices):\n",
    "            events.append({\n",
    "                'event_id': event_id,\n",
    "                'timestamp': idx / sampling_rate,\n",
    "                'amplitude': channel_signal[idx],\n",
    "                'channel': channel_idx,\n",
    "                'event_type': 'peak',\n",
    "                'signal_quality': signal_std,\n",
    "                'prominence': peak_props.get('prominences', [0])[i] if 'prominences' in peak_props else 0\n",
    "            })\n",
    "            event_id += 1\n",
    "        \n",
    "        for i, idx in enumerate(valley_indices):\n",
    "            events.append({\n",
    "                'event_id': event_id,\n",
    "                'timestamp': idx / sampling_rate,\n",
    "                'amplitude': channel_signal[idx],\n",
    "                'channel': channel_idx,\n",
    "                'event_type': 'valley',\n",
    "                'signal_quality': signal_std,\n",
    "                'prominence': valley_props.get('prominences', [0])[i] if 'prominences' in valley_props else 0\n",
    "            })\n",
    "            event_id += 1\n",
    "    \n",
    "    print(f\"üìä Quality control results:\")\n",
    "    print(f\"  Good channels: {qc_stats['good_channels']}\")\n",
    "    print(f\"  Noisy channels (excluded): {qc_stats['noisy_channels']}\")\n",
    "    print(f\"  Flat channels (excluded): {qc_stats['flat_channels']}\")\n",
    "    \n",
    "    return pd.DataFrame(events).sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Example usage of advanced versions:\n",
    "# neural_events_df = extract_neural_events_adaptive(neural_signals, SAMPLING_RATE)\n",
    "# neural_events_df = extract_neural_events_with_qc(neural_signals, SAMPLING_RATE)\n",
    "\n",
    "print(f\"\\nüéØ Neural event extraction complete and ready for causal analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3424fdf4-7710-444d-920b-87a1b5c2d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß RUNNING FIXED KUMO PIPELINE\n",
      "==================================================\n",
      "‚úÖ Found causal_df with 5009609 relationships\n",
      "üöÄ Running FIXED Kumo AI pipeline...\n",
      "============================================================\n",
      "üìä Preparing tables for Kumo AI (with data type fixes)...\n",
      "‚úì Neural events table: 25123 events\n",
      "‚úì Phoneme events table: 46276 phonemes\n",
      "‚úì Causal relationships table: 5009609 edges\n",
      "üîç Validating data types...\n",
      "‚ö†Ô∏è Warning: relationships.phoneme_id has 5009609 NaN values\n",
      "üîó Creating Kumo AI graph (safe mode)...\n",
      "üìã Table information:\n",
      "  neural_events: 25123 rows, 13 columns\n",
      "    Data types: {'event_id': dtype('int64'), 'timestamp': dtype('float64'), 'amplitude': dtype('float32'), 'normalized_amplitude': dtype('float32'), 'prominence': dtype('float64'), 'channel': dtype('int64'), 'event_type': dtype('O'), 'channel_region': dtype('int64'), 'trial_id': dtype('O'), 'sample_index': dtype('int64'), 'timestamp_ms': dtype('float64'), 'channel_group': dtype('int64'), 'amplitude_normalized': dtype('float32')}\n",
      "  phoneme_events: 46276 rows, 12 columns\n",
      "    Data types: {'trial_id': dtype('int64'), 'phoneme_id': dtype('O'), 'phoneme': dtype('O'), 'start_time': dtype('float64'), 'end_time': dtype('float64'), 'duration': dtype('float64'), 'sequence_position': dtype('int64'), 'total_sequence_length': dtype('int64'), 'subject_id': dtype('O'), 'start_time_ms': dtype('float64'), 'duration_ms': dtype('float64'), 'phoneme_category': dtype('O')}\n",
      "  neural_phoneme_edges: 5009609 rows, 11 columns\n",
      "    Data types: {'relationship_id': dtype('int64'), 'neural_event_id': dtype('int64'), 'phoneme_id': dtype('float64'), 'delay_seconds': dtype('float64'), 'delay_ms': dtype('float64'), 'strength': dtype('float64'), 'event_type': dtype('O'), 'channel': dtype('int64'), 'phoneme': dtype('O'), 'trial_id': dtype('int64'), 'strength_category': dtype('O')}\n",
      "üî® Creating graph...\n",
      "‚öôÔ∏è Configuring graph...\n",
      "‚úÖ Graph created successfully!\n",
      "üìà Graph Statistics:\n",
      "  Tables: 3\n",
      "‚ùå Error creating graph: object of type 'LocalTable' has no len()\n",
      "üîç Error details: TypeError: object of type 'LocalTable' has no len()\n",
      "‚ùå Graph creation failed\n",
      "\n",
      "‚ùå Fixed pipeline also failed\n",
      "üí° The dataset might need more preprocessing\n"
     ]
    }
   ],
   "source": [
    "# # Fixed Kumo Graph Creation with Proper Data Type Handling\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import kumoai.experimental.rfm as rfm\n",
    "\n",
    "# def prepare_kumo_tables_fixed(neural_events_df, phoneme_annotations, causal_df):\n",
    "#     \"\"\"\n",
    "#     Prepare tables for Kumo AI with proper data type handling\n",
    "#     \"\"\"\n",
    "#     print(\"üìä Preparing tables for Kumo AI (with data type fixes)...\")\n",
    "    \n",
    "#     # 1. Neural Events Table - Clean copy with proper data types\n",
    "#     neural_table = neural_events_df.copy()\n",
    "    \n",
    "#     # Convert all categorical columns to strings to avoid categorical issues\n",
    "#     for col in neural_table.columns:\n",
    "#         if neural_table[col].dtype.name == 'category':\n",
    "#             neural_table[col] = neural_table[col].astype(str)\n",
    "    \n",
    "#     # Ensure numeric columns are proper numeric types\n",
    "#     numeric_cols = ['event_id', 'timestamp', 'channel', 'amplitude']\n",
    "#     for col in numeric_cols:\n",
    "#         if col in neural_table.columns:\n",
    "#             neural_table[col] = pd.to_numeric(neural_table[col], errors='coerce')\n",
    "    \n",
    "#     # Ensure string columns are strings\n",
    "#     string_cols = ['event_type', 'trial_id']\n",
    "#     for col in string_cols:\n",
    "#         if col in neural_table.columns:\n",
    "#             neural_table[col] = neural_table[col].astype(str)\n",
    "    \n",
    "#     # Add required features with safe data types\n",
    "#     neural_table['timestamp_ms'] = neural_table['timestamp'] * 1000\n",
    "#     neural_table['channel_group'] = neural_table['channel'] // 4\n",
    "    \n",
    "#     # Safe amplitude normalization\n",
    "#     amp_mean = neural_table['amplitude'].mean()\n",
    "#     amp_std = neural_table['amplitude'].std()\n",
    "#     if amp_std > 0:\n",
    "#         neural_table['amplitude_normalized'] = (neural_table['amplitude'] - amp_mean) / amp_std\n",
    "#     else:\n",
    "#         neural_table['amplitude_normalized'] = 0.0\n",
    "    \n",
    "#     print(f\"‚úì Neural events table: {len(neural_table)} events\")\n",
    "    \n",
    "#     # 2. Phoneme Events Table - Clean copy with proper data types\n",
    "#     phoneme_table = phoneme_annotations.copy()\n",
    "    \n",
    "#     # Convert categorical columns to strings\n",
    "#     for col in phoneme_table.columns:\n",
    "#         if phoneme_table[col].dtype.name == 'category':\n",
    "#             phoneme_table[col] = phoneme_table[col].astype(str)\n",
    "    \n",
    "#     # Ensure required columns exist and have correct types\n",
    "#     required_cols = ['phoneme_id', 'phoneme', 'start_time', 'end_time']\n",
    "#     for col in required_cols:\n",
    "#         if col not in phoneme_table.columns:\n",
    "#             if col == 'phoneme_id':\n",
    "#                 phoneme_table['phoneme_id'] = range(len(phoneme_table))\n",
    "#             elif col == 'end_time' and 'start_time' in phoneme_table.columns:\n",
    "#                 phoneme_table['end_time'] = phoneme_table['start_time'] + 0.1  # Default 100ms duration\n",
    "#             else:\n",
    "#                 print(f\"‚ö†Ô∏è Warning: Missing required column {col}\")\n",
    "    \n",
    "#     # Ensure numeric columns\n",
    "#     numeric_cols = ['start_time', 'end_time']\n",
    "#     for col in numeric_cols:\n",
    "#         if col in phoneme_table.columns:\n",
    "#             phoneme_table[col] = pd.to_numeric(phoneme_table[col], errors='coerce')\n",
    "    \n",
    "#     # Ensure string columns\n",
    "#     phoneme_table['phoneme'] = phoneme_table['phoneme'].astype(str)\n",
    "    \n",
    "#     # Add features with safe data types\n",
    "#     phoneme_table['start_time_ms'] = phoneme_table['start_time'] * 1000\n",
    "#     if 'end_time' in phoneme_table.columns:\n",
    "#         phoneme_table['duration_ms'] = (phoneme_table['end_time'] - phoneme_table['start_time']) * 1000\n",
    "#     else:\n",
    "#         phoneme_table['duration_ms'] = 100.0  # Default 100ms\n",
    "    \n",
    "#     # Safe phoneme category extraction\n",
    "#     phoneme_table['phoneme_category'] = phoneme_table['phoneme'].str[:1].fillna('UNK')\n",
    "    \n",
    "#     print(f\"‚úì Phoneme events table: {len(phoneme_table)} phonemes\")\n",
    "    \n",
    "#     # 3. Relationships Table - Clean copy with proper data types\n",
    "#     relationships_table = causal_df.copy()\n",
    "    \n",
    "#     # Convert categorical columns to strings\n",
    "#     for col in relationships_table.columns:\n",
    "#         if relationships_table[col].dtype.name == 'category':\n",
    "#             relationships_table[col] = relationships_table[col].astype(str)\n",
    "    \n",
    "#     # Ensure required edge columns exist\n",
    "#     if 'neural_event_id' not in relationships_table.columns:\n",
    "#         print(\"‚ùå Error: Missing neural_event_id in causal relationships\")\n",
    "#         return None\n",
    "#     if 'phoneme_id' not in relationships_table.columns:\n",
    "#         print(\"‚ùå Error: Missing phoneme_id in causal relationships\")\n",
    "#         return None\n",
    "    \n",
    "#     # Ensure numeric types for edge columns\n",
    "#     relationships_table['neural_event_id'] = pd.to_numeric(relationships_table['neural_event_id'], errors='coerce')\n",
    "#     relationships_table['phoneme_id'] = pd.to_numeric(relationships_table['phoneme_id'], errors='coerce')\n",
    "#     relationships_table['delay_ms'] = pd.to_numeric(relationships_table['delay_ms'], errors='coerce')\n",
    "#     relationships_table['strength'] = pd.to_numeric(relationships_table['strength'], errors='coerce')\n",
    "    \n",
    "#     # Safe categorical feature creation\n",
    "#     try:\n",
    "#         relationships_table['strength_category'] = pd.cut(\n",
    "#             relationships_table['strength'], \n",
    "#             bins=[0, 0.7, 0.85, 1.0], \n",
    "#             labels=['weak', 'medium', 'strong'],\n",
    "#             include_lowest=True\n",
    "#         ).astype(str)\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Warning: Could not create strength categories: {e}\")\n",
    "#         relationships_table['strength_category'] = 'medium'  # Default value\n",
    "    \n",
    "#     # Ensure string columns\n",
    "#     string_cols = ['event_type', 'phoneme']\n",
    "#     for col in string_cols:\n",
    "#         if col in relationships_table.columns:\n",
    "#             relationships_table[col] = relationships_table[col].astype(str)\n",
    "    \n",
    "#     print(f\"‚úì Causal relationships table: {len(relationships_table)} edges\")\n",
    "    \n",
    "#     # 4. Data validation\n",
    "#     print(f\"üîç Validating data types...\")\n",
    "    \n",
    "#     # Check for any remaining categorical columns\n",
    "#     for table_name, table in [('neural_events', neural_table), \n",
    "#                              ('phoneme_events', phoneme_table), \n",
    "#                              ('relationships', relationships_table)]:\n",
    "#         categorical_cols = [col for col in table.columns if table[col].dtype.name == 'category']\n",
    "#         if categorical_cols:\n",
    "#             print(f\"‚ö†Ô∏è Warning: {table_name} still has categorical columns: {categorical_cols}\")\n",
    "    \n",
    "#     # Check for NaN values in key columns\n",
    "#     key_checks = [\n",
    "#         (neural_table, 'event_id', 'neural_events'),\n",
    "#         (phoneme_table, 'phoneme_id', 'phoneme_events'),\n",
    "#         (relationships_table, 'neural_event_id', 'relationships'),\n",
    "#         (relationships_table, 'phoneme_id', 'relationships')\n",
    "#     ]\n",
    "    \n",
    "#     for table, col, table_name in key_checks:\n",
    "#         if col in table.columns:\n",
    "#             nan_count = table[col].isna().sum()\n",
    "#             if nan_count > 0:\n",
    "#                 print(f\"‚ö†Ô∏è Warning: {table_name}.{col} has {nan_count} NaN values\")\n",
    "    \n",
    "#     return {\n",
    "#         'neural_events': neural_table,\n",
    "#         'phoneme_events': phoneme_table,\n",
    "#         'neural_phoneme_edges': relationships_table\n",
    "#     }\n",
    "\n",
    "# def create_kumo_graph_safe(tables):\n",
    "#     \"\"\"\n",
    "#     Create Kumo AI graph with enhanced error handling\n",
    "#     \"\"\"\n",
    "#     print(\"üîó Creating Kumo AI graph (safe mode)...\")\n",
    "    \n",
    "#     try:\n",
    "#         # Display table info before creation\n",
    "#         print(\"üìã Table information:\")\n",
    "#         for table_name, table in tables.items():\n",
    "#             print(f\"  {table_name}: {len(table)} rows, {len(table.columns)} columns\")\n",
    "#             print(f\"    Data types: {dict(table.dtypes)}\")\n",
    "            \n",
    "#             # Check for any remaining issues\n",
    "#             problematic_cols = []\n",
    "#             for col in table.columns:\n",
    "#                 if table[col].dtype.name == 'category':\n",
    "#                     problematic_cols.append(f\"{col} (categorical)\")\n",
    "#                 elif table[col].dtype == 'object':\n",
    "#                     # Check if object column contains mixed types\n",
    "#                     try:\n",
    "#                         sample_values = table[col].dropna().head().tolist()\n",
    "#                         value_types = [type(v).__name__ for v in sample_values]\n",
    "#                         if len(set(value_types)) > 1:\n",
    "#                             problematic_cols.append(f\"{col} (mixed types: {value_types})\")\n",
    "#                     except:\n",
    "#                         pass\n",
    "            \n",
    "#             if problematic_cols:\n",
    "#                 print(f\"    ‚ö†Ô∏è Potential issues: {problematic_cols}\")\n",
    "        \n",
    "#         # Create the graph\n",
    "#         print(\"üî® Creating graph...\")\n",
    "#         graph = rfm.LocalGraph.from_data(tables)\n",
    "        \n",
    "#         # Configure the graph\n",
    "#         print(\"‚öôÔ∏è Configuring graph...\")\n",
    "        \n",
    "#         # Set temporal columns\n",
    "#         if 'neural_events' in tables:\n",
    "#             graph['neural_events'].time_column = 'timestamp'\n",
    "#             graph['neural_events'].primary_key = 'event_id'\n",
    "        \n",
    "#         if 'phoneme_events' in tables:\n",
    "#             graph['phoneme_events'].time_column = 'start_time'\n",
    "#             graph['phoneme_events'].primary_key = 'phoneme_id'\n",
    "        \n",
    "#         # Configure edge table\n",
    "#         if 'neural_phoneme_edges' in tables:\n",
    "#             graph['neural_phoneme_edges'].source_column = 'neural_event_id'\n",
    "#             graph['neural_phoneme_edges'].target_column = 'phoneme_id'\n",
    "#             graph['neural_phoneme_edges'].source_table = 'neural_events'\n",
    "#             graph['neural_phoneme_edges'].target_table = 'phoneme_events'\n",
    "        \n",
    "#         print(\"‚úÖ Graph created successfully!\")\n",
    "        \n",
    "#         # Display graph statistics\n",
    "#         print(f\"üìà Graph Statistics:\")\n",
    "#         print(f\"  Tables: {len(graph.tables)}\")\n",
    "#         for table_name, table in graph.tables.items():\n",
    "#             print(f\"  - {table_name}: {len(table)} rows\")\n",
    "        \n",
    "#         # Try to visualize (this might also fail, so wrap in try-catch)\n",
    "#         try:\n",
    "#             print(\"üé® Visualizing graph schema...\")\n",
    "#             graph.visualize(show_columns=True)\n",
    "#         except Exception as viz_error:\n",
    "#             print(f\"‚ö†Ô∏è Could not visualize graph: {viz_error}\")\n",
    "        \n",
    "#         return graph\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error creating graph: {e}\")\n",
    "#         print(f\"üîç Error details: {type(e).__name__}: {str(e)}\")\n",
    "        \n",
    "#         # Additional debugging\n",
    "#         if \"categorical\" in str(e).lower():\n",
    "#             print(\"üí° This appears to be a categorical data issue.\")\n",
    "#             print(\"   Try running the data cleaning steps again.\")\n",
    "        \n",
    "#         return None\n",
    "\n",
    "# def create_simple_prediction_queries(graph):\n",
    "#     \"\"\"\n",
    "#     Create simplified prediction queries that are less likely to fail\n",
    "#     \"\"\"\n",
    "#     print(\"üß† Creating simplified prediction models...\")\n",
    "    \n",
    "#     try:\n",
    "#         # Simple Neural ‚Üí Phoneme prediction\n",
    "#         neural_to_phoneme_query = {\n",
    "#             'target_table': 'phoneme_events',\n",
    "#             'target_column': 'phoneme',\n",
    "#             'feature_tables': ['neural_events'],\n",
    "#             'features': ['neural_events.event_type', 'neural_events.channel'],\n",
    "#             'time_column': 'start_time',\n",
    "#             'training_window': '2s'\n",
    "#         }\n",
    "        \n",
    "#         # Simple Phoneme ‚Üí Neural prediction\n",
    "#         phoneme_to_neural_query = {\n",
    "#             'target_table': 'neural_events',\n",
    "#             'target_column': 'event_type',\n",
    "#             'feature_tables': ['phoneme_events'],\n",
    "#             'features': ['phoneme_events.phoneme'],\n",
    "#             'time_column': 'timestamp',\n",
    "#             'training_window': '1s'\n",
    "#         }\n",
    "        \n",
    "#         print(\"‚úì Simplified prediction queries created\")\n",
    "#         return neural_to_phoneme_query, phoneme_to_neural_query\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error creating prediction queries: {e}\")\n",
    "#         return None, None\n",
    "\n",
    "# def run_fixed_kumo_pipeline(neural_events_df, phoneme_annotations, causal_df):\n",
    "#     \"\"\"\n",
    "#     Run the Kumo pipeline with enhanced error handling\n",
    "#     \"\"\"\n",
    "#     print(\"üöÄ Running FIXED Kumo AI pipeline...\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # Step 1: Prepare data with proper type handling\n",
    "#     tables = prepare_kumo_tables_fixed(neural_events_df, phoneme_annotations, causal_df)\n",
    "#     if not tables:\n",
    "#         print(\"‚ùå Data preparation failed\")\n",
    "#         return None\n",
    "    \n",
    "#     # Step 2: Create graph with safe mode\n",
    "#     graph = create_kumo_graph_safe(tables)\n",
    "#     if not graph:\n",
    "#         print(\"‚ùå Graph creation failed\")\n",
    "#         return None\n",
    "    \n",
    "#     # Step 3: Try simple predictions\n",
    "#     try:\n",
    "#         print(\"üéØ Attempting basic graph queries...\")\n",
    "        \n",
    "#         # Test basic queries to ensure graph works\n",
    "#         neural_count = graph.query(\"SELECT COUNT(*) as count FROM neural_events\")\n",
    "#         phoneme_count = graph.query(\"SELECT COUNT(*) as count FROM phoneme_events\")\n",
    "        \n",
    "#         print(f\"‚úì Graph queries working:\")\n",
    "#         print(f\"  Neural events: {neural_count['count'].iloc[0]}\")\n",
    "#         print(f\"  Phoneme events: {phoneme_count['count'].iloc[0]}\")\n",
    "        \n",
    "#         # Try to create simplified models\n",
    "#         neural_to_phoneme_query, phoneme_to_neural_query = create_simple_prediction_queries(graph)\n",
    "        \n",
    "#         result = {\n",
    "#             'graph': graph,\n",
    "#             'tables': tables,\n",
    "#             'neural_to_phoneme_query': neural_to_phoneme_query,\n",
    "#             'phoneme_to_neural_query': phoneme_to_neural_query,\n",
    "#             'status': 'graph_created'\n",
    "#         }\n",
    "        \n",
    "#         print(\"‚úÖ Fixed pipeline completed successfully!\")\n",
    "#         print(\"üìä Graph is ready for predictions\")\n",
    "        \n",
    "#         return result\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in pipeline execution: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # ============================================================================\n",
    "# # RUN THE FIXED PIPELINE\n",
    "# # ============================================================================\n",
    "\n",
    "# print(\"üîß RUNNING FIXED KUMO PIPELINE\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# if 'causal_df' in globals() and len(causal_df) > 0:\n",
    "#     print(f\"‚úÖ Found causal_df with {len(causal_df)} relationships\")\n",
    "    \n",
    "#     # Run the fixed pipeline\n",
    "#     fixed_results = run_fixed_kumo_pipeline(neural_events_df, phoneme_annotations, causal_df)\n",
    "    \n",
    "#     if fixed_results and fixed_results['graph']:\n",
    "#         print(f\"\\nüéâ SUCCESS! Graph created successfully!\")\n",
    "#         print(f\"üìä You now have a working Kumo AI graph\")\n",
    "#         print(f\"üîç Try some basic queries:\")\n",
    "        \n",
    "#         # Example queries\n",
    "#         try:\n",
    "#             graph = fixed_results['graph']\n",
    "            \n",
    "#             # Basic statistics\n",
    "#             print(f\"\\nüìà Basic Graph Statistics:\")\n",
    "            \n",
    "#             # Neural events by type\n",
    "#             event_types = graph.query(\"\"\"\n",
    "#                 SELECT event_type, COUNT(*) as count \n",
    "#                 FROM neural_events \n",
    "#                 GROUP BY event_type\n",
    "#             \"\"\")\n",
    "#             print(f\"Event types: {dict(zip(event_types['event_type'], event_types['count']))}\")\n",
    "            \n",
    "#             # Top phonemes\n",
    "#             top_phonemes = graph.query(\"\"\"\n",
    "#                 SELECT phoneme, COUNT(*) as count \n",
    "#                 FROM phoneme_events \n",
    "#                 GROUP BY phoneme \n",
    "#                 ORDER BY count DESC \n",
    "#                 LIMIT 5\n",
    "#             \"\"\")\n",
    "#             print(f\"Top phonemes: {dict(zip(top_phonemes['phoneme'], top_phonemes['count']))}\")\n",
    "            \n",
    "#             # Causal relationship stats\n",
    "#             causal_stats = graph.query(\"\"\"\n",
    "#                 SELECT \n",
    "#                     COUNT(*) as total_edges,\n",
    "#                     AVG(delay_ms) as avg_delay,\n",
    "#                     MIN(delay_ms) as min_delay,\n",
    "#                     MAX(delay_ms) as max_delay\n",
    "#                 FROM neural_phoneme_edges\n",
    "#             \"\"\")\n",
    "#             print(f\"Causal relationships: {causal_stats.iloc[0].to_dict()}\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ö†Ô∏è Could not run example queries: {e}\")\n",
    "        \n",
    "#         print(f\"\\nüéØ Next steps:\")\n",
    "#         print(f\"1. Try training simple models on this graph\")\n",
    "#         print(f\"2. Create prediction queries\")\n",
    "#         print(f\"3. Build real-time prediction system\")\n",
    "        \n",
    "#     else:\n",
    "#         print(f\"\\n‚ùå Fixed pipeline also failed\")\n",
    "#         print(f\"üí° The dataset might need more preprocessing\")\n",
    "        \n",
    "# else:\n",
    "#     print(f\"‚ùå causal_df not found or empty\")\n",
    "#     print(f\"Run the causal relationship creation code first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2548a9b-2563-42f2-a80c-ad34ccbf28dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (0.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d48808ac-17b7-4fa2-ba04-60c328ff50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "# \"\"\"\n",
    "# kumo_graph_final_fix.py - Final comprehensive fix for Kumo AI graph creation\n",
    "# \"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import kumoai.experimental.rfm as rfm\n",
    "\n",
    "# def fix_phoneme_id_issue(causal_df, phoneme_annotations):\n",
    "#     \"\"\"\n",
    "#     Fix the phoneme_id NaN issue by ensuring proper ID mapping\n",
    "#     \"\"\"\n",
    "#     print(\"üîß Fixing phoneme_id mapping issue...\")\n",
    "    \n",
    "#     # Check if phoneme_id in causal_df is string format\n",
    "#     causal_df_fixed = causal_df.copy()\n",
    "    \n",
    "#     # If phoneme_id is string format like \"0_1\", \"1_2\", etc., we need to map to proper IDs\n",
    "#     if 'phoneme_id' in causal_df_fixed.columns:\n",
    "#         # Create a mapping from string phoneme_ids to numeric IDs\n",
    "#         unique_phoneme_ids = phoneme_annotations['phoneme_id'].unique()\n",
    "        \n",
    "#         # Create mapping dictionary\n",
    "#         phoneme_id_mapping = {}\n",
    "#         for i, pid in enumerate(unique_phoneme_ids):\n",
    "#             phoneme_id_mapping[pid] = i\n",
    "        \n",
    "#         # Map the causal_df phoneme_id to the new numeric IDs\n",
    "#         causal_df_fixed['phoneme_id_numeric'] = causal_df_fixed['phoneme_id'].map(phoneme_id_mapping)\n",
    "        \n",
    "#         # If mapping failed, create sequential mapping\n",
    "#         if causal_df_fixed['phoneme_id_numeric'].isna().all():\n",
    "#             print(\"  Creating sequential phoneme ID mapping...\")\n",
    "#             # Get unique phoneme_ids from causal_df\n",
    "#             unique_causal_phoneme_ids = causal_df_fixed['phoneme_id'].unique()\n",
    "#             # Create sequential mapping\n",
    "#             id_mapping = {pid: i for i, pid in enumerate(unique_causal_phoneme_ids)}\n",
    "#             causal_df_fixed['phoneme_id_numeric'] = causal_df_fixed['phoneme_id'].map(id_mapping)\n",
    "        \n",
    "#         # Replace the old phoneme_id column\n",
    "#         causal_df_fixed['phoneme_id'] = causal_df_fixed['phoneme_id_numeric']\n",
    "#         causal_df_fixed = causal_df_fixed.drop('phoneme_id_numeric', axis=1)\n",
    "        \n",
    "#         # Ensure phoneme_annotations has matching numeric IDs\n",
    "#         phoneme_annotations_fixed = phoneme_annotations.copy()\n",
    "#         phoneme_annotations_fixed['phoneme_id'] = range(len(phoneme_annotations_fixed))\n",
    "        \n",
    "#         print(f\"  ‚úì Fixed phoneme_id mapping\")\n",
    "#         print(f\"  ‚úì Causal relationships: {len(causal_df_fixed)} (NaN count: {causal_df_fixed['phoneme_id'].isna().sum()})\")\n",
    "#         print(f\"  ‚úì Phoneme annotations: {len(phoneme_annotations_fixed)}\")\n",
    "        \n",
    "#         return causal_df_fixed, phoneme_annotations_fixed\n",
    "    \n",
    "#     return causal_df, phoneme_annotations\n",
    "\n",
    "# def prepare_kumo_tables_fixed(neural_events_df, phoneme_annotations, causal_df):\n",
    "#     \"\"\"\n",
    "#     Prepare tables for Kumo AI with proper data type handling and all fixes\n",
    "#     \"\"\"\n",
    "#     print(\"üìä Preparing tables for Kumo AI (with comprehensive fixes)...\")\n",
    "    \n",
    "#     # First fix the phoneme_id issue\n",
    "#     causal_df_fixed, phoneme_annotations_fixed = fix_phoneme_id_issue(causal_df, phoneme_annotations)\n",
    "    \n",
    "#     # 1. Neural Events Table - Clean copy with proper data types\n",
    "#     neural_table = neural_events_df.copy()\n",
    "    \n",
    "#     # Convert all categorical columns to strings to avoid categorical issues\n",
    "#     for col in neural_table.columns:\n",
    "#         if neural_table[col].dtype.name == 'category':\n",
    "#             neural_table[col] = neural_table[col].astype(str)\n",
    "    \n",
    "#     # Ensure numeric columns are proper numeric types\n",
    "#     numeric_cols = ['event_id', 'timestamp', 'channel', 'amplitude']\n",
    "#     for col in numeric_cols:\n",
    "#         if col in neural_table.columns:\n",
    "#             neural_table[col] = pd.to_numeric(neural_table[col], errors='coerce')\n",
    "    \n",
    "#     # Ensure string columns are strings\n",
    "#     string_cols = ['event_type', 'trial_id']\n",
    "#     for col in string_cols:\n",
    "#         if col in neural_table.columns:\n",
    "#             neural_table[col] = neural_table[col].astype(str)\n",
    "    \n",
    "#     # Add required features with safe data types\n",
    "#     neural_table['timestamp_ms'] = neural_table['timestamp'] * 1000\n",
    "#     neural_table['channel_group'] = neural_table['channel'] // 4\n",
    "    \n",
    "#     # Safe amplitude normalization\n",
    "#     amp_mean = neural_table['amplitude'].mean()\n",
    "#     amp_std = neural_table['amplitude'].std()\n",
    "#     if amp_std > 0:\n",
    "#         neural_table['amplitude_normalized'] = (neural_table['amplitude'] - amp_mean) / amp_std\n",
    "#     else:\n",
    "#         neural_table['amplitude_normalized'] = 0.0\n",
    "    \n",
    "#     print(f\"‚úì Neural events table: {len(neural_table)} events\")\n",
    "    \n",
    "#     # 2. Phoneme Events Table - Clean copy with proper data types\n",
    "#     phoneme_table = phoneme_annotations_fixed.copy()\n",
    "    \n",
    "#     # Convert categorical columns to strings\n",
    "#     for col in phoneme_table.columns:\n",
    "#         if phoneme_table[col].dtype.name == 'category':\n",
    "#             phoneme_table[col] = phoneme_table[col].astype(str)\n",
    "    \n",
    "#     # Ensure required columns exist and have correct types\n",
    "#     required_cols = ['phoneme_id', 'phoneme', 'start_time', 'end_time']\n",
    "#     for col in required_cols:\n",
    "#         if col not in phoneme_table.columns:\n",
    "#             if col == 'phoneme_id':\n",
    "#                 phoneme_table['phoneme_id'] = range(len(phoneme_table))\n",
    "#             elif col == 'end_time' and 'start_time' in phoneme_table.columns:\n",
    "#                 phoneme_table['end_time'] = phoneme_table['start_time'] + 0.1  # Default 100ms duration\n",
    "#             else:\n",
    "#                 print(f\"‚ö†Ô∏è Warning: Missing required column {col}\")\n",
    "    \n",
    "#     # Ensure numeric columns\n",
    "#     numeric_cols = ['phoneme_id', 'start_time', 'end_time']\n",
    "#     for col in numeric_cols:\n",
    "#         if col in phoneme_table.columns:\n",
    "#             phoneme_table[col] = pd.to_numeric(phoneme_table[col], errors='coerce')\n",
    "    \n",
    "#     # Ensure string columns\n",
    "#     phoneme_table['phoneme'] = phoneme_table['phoneme'].astype(str)\n",
    "    \n",
    "#     # Add features with safe data types\n",
    "#     phoneme_table['start_time_ms'] = phoneme_table['start_time'] * 1000\n",
    "#     if 'end_time' in phoneme_table.columns:\n",
    "#         phoneme_table['duration_ms'] = (phoneme_table['end_time'] - phoneme_table['start_time']) * 1000\n",
    "#     else:\n",
    "#         phoneme_table['duration_ms'] = 100.0  # Default 100ms\n",
    "    \n",
    "#     # Safe phoneme category extraction\n",
    "#     phoneme_table['phoneme_category'] = phoneme_table['phoneme'].str[:1].fillna('UNK')\n",
    "    \n",
    "#     print(f\"‚úì Phoneme events table: {len(phoneme_table)} phonemes\")\n",
    "    \n",
    "#     # 3. Relationships Table - Clean copy with proper data types\n",
    "#     relationships_table = causal_df_fixed.copy()\n",
    "    \n",
    "#     # Convert categorical columns to strings\n",
    "#     for col in relationships_table.columns:\n",
    "#         if relationships_table[col].dtype.name == 'category':\n",
    "#             relationships_table[col] = relationships_table[col].astype(str)\n",
    "    \n",
    "#     # Ensure required edge columns exist\n",
    "#     if 'neural_event_id' not in relationships_table.columns:\n",
    "#         print(\"‚ùå Error: Missing neural_event_id in causal relationships\")\n",
    "#         return None\n",
    "#     if 'phoneme_id' not in relationships_table.columns:\n",
    "#         print(\"‚ùå Error: Missing phoneme_id in causal relationships\")\n",
    "#         return None\n",
    "    \n",
    "#     # Ensure numeric types for edge columns\n",
    "#     relationships_table['neural_event_id'] = pd.to_numeric(relationships_table['neural_event_id'], errors='coerce')\n",
    "#     relationships_table['phoneme_id'] = pd.to_numeric(relationships_table['phoneme_id'], errors='coerce')\n",
    "#     relationships_table['delay_ms'] = pd.to_numeric(relationships_table['delay_ms'], errors='coerce')\n",
    "#     relationships_table['strength'] = pd.to_numeric(relationships_table['strength'], errors='coerce')\n",
    "    \n",
    "#     # Remove any rows with NaN in key columns\n",
    "#     before_count = len(relationships_table)\n",
    "#     relationships_table = relationships_table.dropna(subset=['neural_event_id', 'phoneme_id'])\n",
    "#     after_count = len(relationships_table)\n",
    "    \n",
    "#     if before_count != after_count:\n",
    "#         print(f\"  Removed {before_count - after_count} rows with NaN IDs\")\n",
    "    \n",
    "#     # Safe categorical feature creation\n",
    "#     try:\n",
    "#         relationships_table['strength_category'] = pd.cut(\n",
    "#             relationships_table['strength'], \n",
    "#             bins=[0, 0.7, 0.85, 1.0], \n",
    "#             labels=['weak', 'medium', 'strong'],\n",
    "#             include_lowest=True\n",
    "#         ).astype(str)\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Warning: Could not create strength categories: {e}\")\n",
    "#         relationships_table['strength_category'] = 'medium'  # Default value\n",
    "    \n",
    "#     # Ensure string columns\n",
    "#     string_cols = ['event_type', 'phoneme']\n",
    "#     for col in string_cols:\n",
    "#         if col in relationships_table.columns:\n",
    "#             relationships_table[col] = relationships_table[col].astype(str)\n",
    "    \n",
    "#     print(f\"‚úì Causal relationships table: {len(relationships_table)} edges\")\n",
    "    \n",
    "#     # 4. Final data validation\n",
    "#     print(f\"üîç Final validation...\")\n",
    "    \n",
    "#     # Check for any remaining categorical columns\n",
    "#     for table_name, table in [('neural_events', neural_table), \n",
    "#                              ('phoneme_events', phoneme_table), \n",
    "#                              ('relationships', relationships_table)]:\n",
    "#         categorical_cols = [col for col in table.columns if table[col].dtype.name == 'category']\n",
    "#         if categorical_cols:\n",
    "#             print(f\"‚ö†Ô∏è Warning: {table_name} still has categorical columns: {categorical_cols}\")\n",
    "    \n",
    "#     # Check for NaN values in key columns\n",
    "#     key_checks = [\n",
    "#         (neural_table, 'event_id', 'neural_events'),\n",
    "#         (phoneme_table, 'phoneme_id', 'phoneme_events'),\n",
    "#         (relationships_table, 'neural_event_id', 'relationships'),\n",
    "#         (relationships_table, 'phoneme_id', 'relationships')\n",
    "#     ]\n",
    "    \n",
    "#     validation_passed = True\n",
    "#     for table, col, table_name in key_checks:\n",
    "#         if col in table.columns:\n",
    "#             nan_count = table[col].isna().sum()\n",
    "#             if nan_count > 0:\n",
    "#                 print(f\"‚ö†Ô∏è Warning: {table_name}.{col} has {nan_count} NaN values\")\n",
    "#                 validation_passed = False\n",
    "    \n",
    "#     if validation_passed:\n",
    "#         print(\"‚úÖ All critical columns are clean\")\n",
    "    \n",
    "#     return {\n",
    "#         'neural_events': neural_table,\n",
    "#         'phoneme_events': phoneme_table,\n",
    "#         'neural_phoneme_edges': relationships_table\n",
    "#     }\n",
    "\n",
    "# def check_kumo_capabilities(graph):\n",
    "#     \"\"\"Check which methods are available in this Kumo version\"\"\"\n",
    "    \n",
    "#     print(\"üîç Checking Kumo AI capabilities...\")\n",
    "    \n",
    "#     capabilities = {\n",
    "#         'query': hasattr(graph, 'query'),\n",
    "#         'visualize': hasattr(graph, 'visualize'),\n",
    "#         'train': hasattr(graph, 'train'),\n",
    "#         'tables': hasattr(graph, 'tables'),\n",
    "#         'get_table': hasattr(graph, 'get_table'),\n",
    "#         'create_prediction': hasattr(graph, 'create_prediction'),\n",
    "#         'fit': hasattr(graph, 'fit')\n",
    "#     }\n",
    "    \n",
    "#     print(\"üìã Available methods:\")\n",
    "#     for method, available in capabilities.items():\n",
    "#         status = \"‚úÖ\" if available else \"‚ùå\"\n",
    "#         print(f\"  {status} {method}\")\n",
    "    \n",
    "#     return capabilities\n",
    "\n",
    "# def get_table_data(graph, table_name):\n",
    "#     \"\"\"Get table data using available methods\"\"\"\n",
    "    \n",
    "#     try:\n",
    "#         # Method 1: Direct table access\n",
    "#         if hasattr(graph, 'tables') and table_name in graph.tables:\n",
    "#             table = graph.tables[table_name]\n",
    "            \n",
    "#             # Convert LocalTable to DataFrame if possible\n",
    "#             if hasattr(table, 'to_pandas'):\n",
    "#                 return table.to_pandas()\n",
    "#             elif hasattr(table, 'data'):\n",
    "#                 return table.data\n",
    "#             elif hasattr(table, 'df'):\n",
    "#                 return table.df\n",
    "#             else:\n",
    "#                 print(f\"‚ö†Ô∏è Unknown table format for {table_name}\")\n",
    "#                 return None\n",
    "                \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error accessing table {table_name}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def create_kumo_graph_safe(tables):\n",
    "#     \"\"\"\n",
    "#     Create Kumo AI graph with enhanced error handling and compatibility checks\n",
    "#     \"\"\"\n",
    "#     print(\"üîó Creating Kumo AI graph (safe mode with compatibility)...\")\n",
    "    \n",
    "#     try:\n",
    "#         # Display basic table info\n",
    "#         print(\"üìã Table summary:\")\n",
    "#         for table_name, table in tables.items():\n",
    "#             print(f\"  {table_name}: {len(table)} rows\")\n",
    "        \n",
    "#         # Create the graph\n",
    "#         print(\"üî® Creating graph...\")\n",
    "#         graph = rfm.LocalGraph.from_data(tables)\n",
    "        \n",
    "#         # Configure the graph\n",
    "#         print(\"‚öôÔ∏è Configuring graph...\")\n",
    "        \n",
    "#         # Set temporal columns and primary keys\n",
    "#         if 'neural_events' in tables:\n",
    "#             graph['neural_events'].time_column = 'timestamp'\n",
    "#             graph['neural_events'].primary_key = 'event_id'\n",
    "        \n",
    "#         if 'phoneme_events' in tables:\n",
    "#             graph['phoneme_events'].time_column = 'start_time'\n",
    "#             graph['phoneme_events'].primary_key = 'phoneme_id'\n",
    "        \n",
    "#         # Configure edge table\n",
    "#         if 'neural_phoneme_edges' in tables:\n",
    "#             graph['neural_phoneme_edges'].source_column = 'neural_event_id'\n",
    "#             graph['neural_phoneme_edges'].target_column = 'phoneme_id'\n",
    "#             graph['neural_phoneme_edges'].source_table = 'neural_events'\n",
    "#             graph['neural_phoneme_edges'].target_table = 'phoneme_events'\n",
    "        \n",
    "#         print(\"‚úÖ Graph created and configured successfully!\")\n",
    "        \n",
    "#         # Check capabilities\n",
    "#         capabilities = check_kumo_capabilities(graph)\n",
    "        \n",
    "#         # Test basic functionality without using len() on LocalTable\n",
    "#         print(\"üß™ Testing graph functionality...\")\n",
    "        \n",
    "#         try:\n",
    "#             # Test queries if available\n",
    "#             if capabilities.get('query'):\n",
    "#                 neural_count_result = graph.query(\"SELECT COUNT(*) as count FROM neural_events\")\n",
    "#                 phoneme_count_result = graph.query(\"SELECT COUNT(*) as count FROM phoneme_events\")\n",
    "#                 edges_count_result = graph.query(\"SELECT COUNT(*) as count FROM neural_phoneme_edges\")\n",
    "                \n",
    "#                 neural_count = neural_count_result['count'].iloc[0]\n",
    "#                 phoneme_count = phoneme_count_result['count'].iloc[0]\n",
    "#                 edges_count = edges_count_result['count'].iloc[0]\n",
    "                \n",
    "#                 print(f\"‚úÖ Graph queries successful:\")\n",
    "#                 print(f\"  Neural events: {neural_count}\")\n",
    "#                 print(f\"  Phoneme events: {phoneme_count}\")\n",
    "#                 print(f\"  Edges: {edges_count}\")\n",
    "#             else:\n",
    "#                 print(\"‚ö†Ô∏è Query method not available, using table access instead\")\n",
    "#                 # Try to get basic stats through table access\n",
    "#                 for table_name in ['neural_events', 'phoneme_events', 'neural_phoneme_edges']:\n",
    "#                     table_data = get_table_data(graph, table_name)\n",
    "#                     if table_data is not None:\n",
    "#                         print(f\"  {table_name}: {len(table_data)} rows\")\n",
    "                \n",
    "#         except Exception as query_error:\n",
    "#             print(f\"‚ö†Ô∏è Query test failed: {query_error}\")\n",
    "        \n",
    "#         # Try visualization (optional)\n",
    "#         if capabilities.get('visualize'):\n",
    "#             try:\n",
    "#                 print(\"üé® Attempting visualization...\")\n",
    "#                 graph.visualize(show_columns=True)\n",
    "#                 print(\"‚úÖ Visualization successful\")\n",
    "#             except Exception as viz_error:\n",
    "#                 print(f\"‚ö†Ô∏è Visualization failed: {viz_error}\")\n",
    "#         else:\n",
    "#             print(\"‚ö†Ô∏è Visualization not available in this Kumo version\")\n",
    "        \n",
    "#         return graph\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error creating graph: {e}\")\n",
    "#         print(f\"üîç Error details: {type(e).__name__}: {str(e)}\")\n",
    "        \n",
    "#         # Additional debugging\n",
    "#         if \"categorical\" in str(e).lower():\n",
    "#             print(\"üí° This appears to be a categorical data issue.\")\n",
    "#             print(\"   Try running the data cleaning steps again.\")\n",
    "        \n",
    "#         return None\n",
    "\n",
    "# def create_prediction_framework(graph):\n",
    "#     \"\"\"\n",
    "#     Create prediction framework compatible with available Kumo methods\n",
    "#     \"\"\"\n",
    "#     print(\"üß† Creating prediction framework...\")\n",
    "    \n",
    "#     capabilities = check_kumo_capabilities(graph)\n",
    "    \n",
    "#     try:\n",
    "#         # Method 1: Try modern RFM approach\n",
    "#         if capabilities.get('train'):\n",
    "#             print(\"üöÄ Using RFM training approach...\")\n",
    "            \n",
    "#             # Create prediction queries\n",
    "#             neural_to_phoneme_query = rfm.PredictionQuery(\n",
    "#                 target_table=\"phoneme_events\",\n",
    "#                 target_column=\"phoneme\",\n",
    "#                 feature_tables=[\"neural_events\"],\n",
    "#                 time_column=\"start_time\",\n",
    "#                 features=[\"neural_events.event_type\", \"neural_events.channel\"]\n",
    "#             )\n",
    "            \n",
    "#             phoneme_to_neural_query = rfm.PredictionQuery(\n",
    "#                 target_table=\"neural_events\", \n",
    "#                 target_column=\"event_type\",\n",
    "#                 feature_tables=[\"phoneme_events\"],\n",
    "#                 time_column=\"timestamp\",\n",
    "#                 features=[\"phoneme_events.phoneme\"]\n",
    "#             )\n",
    "            \n",
    "#             return {\n",
    "#                 'neural_to_phoneme_query': neural_to_phoneme_query,\n",
    "#                 'phoneme_to_neural_query': phoneme_to_neural_query,\n",
    "#                 'method': 'rfm_modern'\n",
    "#             }\n",
    "        \n",
    "#         # Method 2: Try simple dictionary-based queries\n",
    "#         else:\n",
    "#             print(\"üöÄ Using simple prediction queries...\")\n",
    "            \n",
    "#             neural_to_phoneme_query = {\n",
    "#                 'target_table': 'phoneme_events',\n",
    "#                 'target_column': 'phoneme',\n",
    "#                 'feature_tables': ['neural_events'],\n",
    "#                 'features': ['neural_events.event_type', 'neural_events.channel'],\n",
    "#                 'time_column': 'start_time',\n",
    "#                 'training_window': '2s'\n",
    "#             }\n",
    "            \n",
    "#             phoneme_to_neural_query = {\n",
    "#                 'target_table': 'neural_events',\n",
    "#                 'target_column': 'event_type',\n",
    "#                 'feature_tables': ['phoneme_events'],\n",
    "#                 'features': ['phoneme_events.phoneme'],\n",
    "#                 'time_column': 'timestamp',\n",
    "#                 'training_window': '1s'\n",
    "#             }\n",
    "            \n",
    "#             return {\n",
    "#                 'neural_to_phoneme_query': neural_to_phoneme_query,\n",
    "#                 'phoneme_to_neural_query': phoneme_to_neural_query,\n",
    "#                 'method': 'simple_dict'\n",
    "#             }\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error creating prediction framework: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def run_fixed_kumo_pipeline(neural_events_df, phoneme_annotations, causal_df):\n",
    "#     \"\"\"\n",
    "#     Run the Kumo pipeline with all fixes and compatibility handling\n",
    "#     \"\"\"\n",
    "#     print(\"üöÄ Running COMPREHENSIVE FIXED Kumo AI pipeline...\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # Step 1: Prepare data with all fixes\n",
    "#     tables = prepare_kumo_tables_fixed(neural_events_df, phoneme_annotations, causal_df)\n",
    "#     if not tables:\n",
    "#         print(\"‚ùå Data preparation failed\")\n",
    "#         return None\n",
    "    \n",
    "#     # Step 2: Create graph with safe mode and compatibility\n",
    "#     graph = create_kumo_graph_safe(tables)\n",
    "#     if not graph:\n",
    "#         print(\"‚ùå Graph creation failed\")\n",
    "#         return None\n",
    "    \n",
    "#     # Step 3: Create prediction framework\n",
    "#     prediction_framework = create_prediction_framework(graph)\n",
    "    \n",
    "#     # Step 4: Analyze data using compatible methods\n",
    "#     try:\n",
    "#         print(\"üìä Analyzing graph data...\")\n",
    "        \n",
    "#         analysis_results = {}\n",
    "#         table_names = ['neural_events', 'phoneme_events', 'neural_phoneme_edges']\n",
    "        \n",
    "#         for table_name in table_names:\n",
    "#             table_data = get_table_data(graph, table_name)\n",
    "#             if table_data is not None:\n",
    "#                 analysis_results[table_name] = table_data\n",
    "#                 print(f\"  ‚úÖ {table_name}: {len(table_data)} rows\")\n",
    "        \n",
    "#         # Basic statistics if we have data\n",
    "#         if 'neural_events' in analysis_results:\n",
    "#             neural_df = analysis_results['neural_events']\n",
    "#             if 'event_type' in neural_df.columns:\n",
    "#                 event_counts = neural_df['event_type'].value_counts()\n",
    "#                 print(f\"  üìà Neural event types: {dict(event_counts)}\")\n",
    "        \n",
    "#         if 'phoneme_events' in analysis_results:\n",
    "#             phoneme_df = analysis_results['phoneme_events']\n",
    "#             if 'phoneme' in phoneme_df.columns:\n",
    "#                 top_phonemes = phoneme_df['phoneme'].value_counts().head(5)\n",
    "#                 print(f\"  üìà Top 5 phonemes: {list(top_phonemes.index)}\")\n",
    "        \n",
    "#         if 'neural_phoneme_edges' in analysis_results:\n",
    "#             edges_df = analysis_results['neural_phoneme_edges']\n",
    "#             if 'delay_ms' in edges_df.columns:\n",
    "#                 avg_delay = edges_df['delay_ms'].mean()\n",
    "#                 print(f\"  üìà Average causal delay: {avg_delay:.1f}ms\")\n",
    "        \n",
    "#     except Exception as analysis_error:\n",
    "#         print(f\"‚ö†Ô∏è Analysis failed: {analysis_error}\")\n",
    "#         analysis_results = {}\n",
    "    \n",
    "#     result = {\n",
    "#         'graph': graph,\n",
    "#         'tables': tables,\n",
    "#         'prediction_framework': prediction_framework,\n",
    "#         'analysis_results': analysis_results,\n",
    "#         'status': 'success'\n",
    "#     }\n",
    "    \n",
    "#     print(\"‚úÖ Comprehensive fixed pipeline completed successfully!\")\n",
    "#     print(\"üìä Graph is ready for neural-phoneme predictions\")\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# # ============================================================================\n",
    "# # MAIN EXECUTION\n",
    "# # ============================================================================\n",
    "\n",
    "# def main():\n",
    "#     print(\"üîß RUNNING COMPREHENSIVE FIXED KUMO PIPELINE\")\n",
    "#     print(\"=\" * 50)\n",
    "    \n",
    "#     # Check for required variables\n",
    "#     required_vars = ['neural_events_df', 'phoneme_annotations', 'causal_df']\n",
    "#     missing_vars = []\n",
    "    \n",
    "#     for var in required_vars:\n",
    "#         if var not in globals():\n",
    "#             missing_vars.append(var)\n",
    "    \n",
    "#     if missing_vars:\n",
    "#         print(f\"‚ùå Missing required variables: {missing_vars}\")\n",
    "#         print(\"Make sure you have run the previous steps to create these DataFrames\")\n",
    "#         return None\n",
    "    \n",
    "#     # Check data availability\n",
    "#     print(f\"‚úÖ Found all required data:\")\n",
    "#     print(f\"  neural_events_df: {len(neural_events_df)} events\")\n",
    "#     print(f\"  phoneme_annotations: {len(phoneme_annotations)} phonemes\") \n",
    "#     print(f\"  causal_df: {len(causal_df)} relationships\")\n",
    "    \n",
    "#     # Run the comprehensive fixed pipeline\n",
    "#     comprehensive_results = run_fixed_kumo_pipeline(neural_events_df, phoneme_annotations, causal_df)\n",
    "    \n",
    "#     if comprehensive_results and comprehensive_results.get('graph'):\n",
    "#         print(f\"\\nüéâ COMPREHENSIVE SUCCESS!\")\n",
    "#         print(f\"‚úÖ Kumo AI graph created and working\")\n",
    "#         print(f\"‚úÖ Compatible with your Kumo version\")\n",
    "#         print(f\"‚úÖ Ready for neural-phoneme predictions\")\n",
    "        \n",
    "#         print(f\"\\nüéØ What you can do now:\")\n",
    "#         print(f\"1. Access table data: graph.tables['table_name']\")\n",
    "#         print(f\"2. Train prediction models (if available)\")\n",
    "#         print(f\"3. Build custom neural-phoneme classifiers\")\n",
    "#         print(f\"4. Create real-time BCI applications\")\n",
    "        \n",
    "#         return comprehensive_results\n",
    "#     else:\n",
    "#         print(f\"\\n‚ùå Comprehensive pipeline failed\")\n",
    "#         return None\n",
    "\n",
    "# # Install graphviz instructions\n",
    "# def show_graphviz_install():\n",
    "#     \"\"\"Show graphviz installation instructions\"\"\"\n",
    "#     print(\"\\nüì¶ GRAPHVIZ INSTALLATION (if needed):\")\n",
    "#     print(\"For Lambda Labs: sudo apt-get update && sudo apt-get install -y graphviz\")\n",
    "#     print(\"Then: pip install graphviz\")\n",
    "\n",
    "# # Run if this file is executed directly\n",
    "# if __name__ == \"__main__\":\n",
    "#     show_graphviz_install()\n",
    "#     main()\n",
    "# else:\n",
    "#     # Run automatically when imported\n",
    "#     if 'neural_events_df' in globals() and 'phoneme_annotations' in globals() and 'causal_df' in globals():\n",
    "#         print(\"üöÄ Auto-running comprehensive fixed Kumo pipeline...\")\n",
    "#         comprehensive_results = main()\n",
    "#         if comprehensive_results:\n",
    "#             print(\"‚úÖ Comprehensive pipeline completed! Results stored in 'comprehensive_results' variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0af0d7d-fa98-4abc-a542-ed473aaee1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ USAGE INSTRUCTIONS:\n",
      "==============================\n",
      "1. Make sure you have the required packages:\n",
      "   pip install matplotlib seaborn plotly networkx\n",
      "\n",
      "2. Run the visualization pipeline:\n",
      "   dirs = main_visualization_pipeline(neural_events_df, phoneme_annotations, causal_df, graph)\n",
      "\n",
      "3. View your visualizations in the graphs/ directory\n",
      "4. Open graphs/summary_reports/analysis_summary.html in a browser\n",
      "\n",
      "‚úÖ Found all required data - running visualization pipeline...\n",
      "üé® STARTING COMPREHENSIVE VISUALIZATION PIPELINE\n",
      "============================================================\n",
      "üìÅ Creating visualization directory structure...\n",
      "  ‚úì graphs\n",
      "  ‚úì graphs/neural_events\n",
      "  ‚úì graphs/phoneme_analysis\n",
      "  ‚úì graphs/causal_relationships\n",
      "  ‚úì graphs/temporal_analysis\n",
      "  ‚úì graphs/channel_analysis\n",
      "  ‚úì graphs/interactive\n",
      "  ‚úì graphs/network_graphs\n",
      "  ‚úì graphs/summary_reports\n",
      "  ‚úì graphs/kumo_graphs\n",
      "üß† Creating neural events visualizations...\n",
      "  ‚úì Saved 5 neural events visualizations\n",
      "üó£Ô∏è Creating phoneme analysis visualizations...\n",
      "  ‚úì Saved 4 phoneme analysis visualizations\n",
      "üîó Creating causal relationships visualizations...\n",
      "  ‚úì Saved 4 causal relationships visualizations\n",
      "‚è∞ Creating temporal analysis visualizations...\n",
      "  ‚úì Saved 2 temporal analysis visualizations\n",
      "üì° Creating channel analysis visualizations...\n",
      "  ‚úì Saved 3 channel analysis visualizations\n",
      "üîÑ Creating interactive visualizations...\n",
      "  ‚úì Saved 4 interactive visualizations\n",
      "üï∏Ô∏è Creating network graph visualizations...\n",
      "  ‚úì Saved network graph and statistics\n",
      "üìã Creating summary report...\n",
      "  ‚úì Saved HTML and text summary reports\n",
      "\n",
      "üéâ VISUALIZATION PIPELINE COMPLETE!\n",
      "üìÅ All visualizations saved to: graphs\n",
      "üìã Summary report: graphs/summary_reports/analysis_summary.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style for better looking plots - multiple options:\n",
    "\n",
    "# Option 1: Modern seaborn style (recommended)\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    # Fallback styles that work with current seaborn/matplotlib\n",
    "    plt.style.use('default')\n",
    "    sns.set_theme(style=\"whitegrid\")  # Modern seaborn approach\n",
    "\n",
    "# Option 2: Classic seaborn styles (if available)\n",
    "# plt.style.use('seaborn')  # Generic seaborn\n",
    "# plt.style.use('ggplot')   # ggplot2-inspired\n",
    "# plt.style.use('bmh')      # Bayesian Methods for Hackers style\n",
    "\n",
    "# Option 3: Pure matplotlib styles (always work)\n",
    "# plt.style.use('default')\n",
    "# plt.style.use('classic') \n",
    "# plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Set color palette\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "def setup_visualization_directories():\n",
    "    \"\"\"Create organized directory structure for visualizations\"\"\"\n",
    "    \n",
    "    base_dir = Path(\"graphs\")\n",
    "    \n",
    "    directories = {\n",
    "        'base': base_dir,\n",
    "        'neural_events': base_dir / \"neural_events\",\n",
    "        'phoneme_analysis': base_dir / \"phoneme_analysis\", \n",
    "        'causal_relationships': base_dir / \"causal_relationships\",\n",
    "        'temporal_analysis': base_dir / \"temporal_analysis\",\n",
    "        'channel_analysis': base_dir / \"channel_analysis\",\n",
    "        'interactive': base_dir / \"interactive\",\n",
    "        'network_graphs': base_dir / \"network_graphs\",\n",
    "        'summary_reports': base_dir / \"summary_reports\",\n",
    "        'kumo_graphs': base_dir / \"kumo_graphs\"\n",
    "    }\n",
    "    \n",
    "    print(\"Creating visualization directory structure...\")\n",
    "    for name, path in directories.items():\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  ‚úì {path}\")\n",
    "    \n",
    "    return directories\n",
    "\n",
    "def save_neural_events_visualizations(neural_events_df, dirs):\n",
    "    \"\"\"Create and save neural events visualizations\"\"\"\n",
    "    \n",
    "    print(\"Creating neural events visualizations...\")\n",
    "    \n",
    "    # 1. Event type distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    event_counts = neural_events_df['event_type'].value_counts()\n",
    "    plt.pie(event_counts.values, labels=event_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Neural Event Type Distribution')\n",
    "    plt.savefig(dirs['neural_events'] / 'event_type_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Events over time\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    neural_events_df.groupby(neural_events_df['timestamp'].round(1)).size().plot()\n",
    "    plt.title('Neural Events Over Time')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Number of Events')\n",
    "    \n",
    "    # 3. Channel activity heatmap\n",
    "    plt.subplot(2, 1, 2)\n",
    "    channel_activity = neural_events_df.groupby(['channel', neural_events_df['timestamp'].round(1)]).size().unstack(fill_value=0)\n",
    "    sns.heatmap(channel_activity.iloc[:, ::10], cmap='viridis', cbar_kws={'label': 'Event Count'})\n",
    "    plt.title('Channel Activity Heatmap')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Channel')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['neural_events'] / 'neural_activity_timeline.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Amplitude distribution by event type\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    neural_events_df.boxplot(column='amplitude', by='event_type', ax=plt.gca())\n",
    "    plt.title('Amplitude Distribution by Event Type')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.savefig(dirs['neural_events'] / 'amplitude_by_event_type.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Channel region analysis\n",
    "    if 'channel_region' in neural_events_df.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        region_counts = neural_events_df['channel_region'].value_counts().sort_index()\n",
    "        plt.bar(region_counts.index, region_counts.values)\n",
    "        plt.title('Events by Channel Region')\n",
    "        plt.xlabel('Channel Region')\n",
    "        plt.ylabel('Number of Events')\n",
    "        plt.savefig(dirs['channel_analysis'] / 'events_by_region.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"   Saved 5 neural events visualizations\")\n",
    "\n",
    "def save_phoneme_analysis_visualizations(phoneme_annotations, dirs):\n",
    "    \"\"\"Create and save phoneme analysis visualizations\"\"\"\n",
    "    \n",
    "    print(\"Creating phoneme analysis visualizations...\")\n",
    "    \n",
    "    # 1. Phoneme frequency distribution\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    top_phonemes = phoneme_annotations['phoneme'].value_counts().head(20)\n",
    "    plt.bar(range(len(top_phonemes)), top_phonemes.values)\n",
    "    plt.xticks(range(len(top_phonemes)), top_phonemes.index, rotation=45)\n",
    "    plt.title('Top 20 Most Frequent Phonemes')\n",
    "    plt.xlabel('Phoneme')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['phoneme_analysis'] / 'phoneme_frequency.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Phoneme duration analysis\n",
    "    if 'duration' in phoneme_annotations.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.hist(phoneme_annotations['duration'], bins=50, alpha=0.7, edgecolor='black')\n",
    "        plt.title('Phoneme Duration Distribution')\n",
    "        plt.xlabel('Duration (seconds)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.axvline(phoneme_annotations['duration'].mean(), color='red', linestyle='--', label=f\"Mean: {phoneme_annotations['duration'].mean():.3f}s\")\n",
    "        plt.legend()\n",
    "        plt.savefig(dirs['phoneme_analysis'] / 'phoneme_duration_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 3. Phoneme timeline\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sample_phonemes = phoneme_annotations.head(100)  # Sample for readability\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(sample_phonemes['phoneme'].unique())))\n",
    "    phoneme_colors = dict(zip(sample_phonemes['phoneme'].unique(), colors))\n",
    "    \n",
    "    for idx, row in sample_phonemes.iterrows():\n",
    "        plt.barh(idx, row['duration'] if 'duration' in row else 0.1, \n",
    "                left=row['start_time'], color=phoneme_colors[row['phoneme']], alpha=0.7)\n",
    "    \n",
    "    plt.title('Phoneme Timeline (First 100 phonemes)')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Phoneme Index')\n",
    "    plt.savefig(dirs['phoneme_analysis'] / 'phoneme_timeline.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Sequence position analysis\n",
    "    if 'sequence_position' in phoneme_annotations.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        position_counts = phoneme_annotations['sequence_position'].value_counts().sort_index()\n",
    "        plt.plot(position_counts.index, position_counts.values, marker='o')\n",
    "        plt.title('Phoneme Count by Sequence Position')\n",
    "        plt.xlabel('Position in Sequence')\n",
    "        plt.ylabel('Number of Phonemes')\n",
    "        plt.savefig(dirs['phoneme_analysis'] / 'sequence_position_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"  ‚úì Saved 4 phoneme analysis visualizations\")\n",
    "\n",
    "def save_causal_relationships_visualizations(causal_df, dirs):\n",
    "    \"\"\"Create and save causal relationships visualizations\"\"\"\n",
    "    \n",
    "    print(\"Creating causal relationships visualizations...\")\n",
    "    \n",
    "    # 1. Delay distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(causal_df['delay_ms'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.title('Causal Delay Distribution')\n",
    "    plt.xlabel('Delay (milliseconds)')\n",
    "    plt.ylabel('Number of Relationships')\n",
    "    plt.axvline(causal_df['delay_ms'].mean(), color='red', linestyle='--', \n",
    "                label=f\"Mean: {causal_df['delay_ms'].mean():.1f}ms\")\n",
    "    plt.legend()\n",
    "    plt.savefig(dirs['causal_relationships'] / 'delay_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Strength vs Delay scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(causal_df['delay_ms'], causal_df['strength'], alpha=0.1, s=1)\n",
    "    plt.xlabel('Delay (ms)')\n",
    "    plt.ylabel('Relationship Strength')\n",
    "    plt.title('Relationship Strength vs Delay')\n",
    "    plt.savefig(dirs['causal_relationships'] / 'strength_vs_delay.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Top phoneme-channel combinations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    top_combinations = causal_df.groupby(['phoneme', 'channel']).size().sort_values(ascending=False).head(20)\n",
    "    \n",
    "    # Create heatmap data\n",
    "    phonemes = [combo[0] for combo in top_combinations.index]\n",
    "    channels = [combo[1] for combo in top_combinations.index]\n",
    "    \n",
    "    # Create a matrix for heatmap\n",
    "    unique_phonemes = list(set(phonemes))\n",
    "    unique_channels = list(set(channels))\n",
    "    \n",
    "    matrix = np.zeros((len(unique_phonemes), len(unique_channels)))\n",
    "    for (phoneme, channel), count in top_combinations.items():\n",
    "        i = unique_phonemes.index(phoneme)\n",
    "        j = unique_channels.index(channel)\n",
    "        matrix[i, j] = count\n",
    "    \n",
    "    sns.heatmap(matrix, xticklabels=unique_channels, yticklabels=unique_phonemes, \n",
    "                annot=True, fmt='.0f', cmap='viridis')\n",
    "    plt.title('Top Phoneme-Channel Relationships')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Phoneme')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['causal_relationships'] / 'phoneme_channel_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Event type analysis\n",
    "    if 'event_type' in causal_df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        event_type_counts = causal_df['event_type'].value_counts()\n",
    "        plt.pie(event_type_counts.values, labels=event_type_counts.index, autopct='%1.1f%%')\n",
    "        plt.title('Causal Relationships by Neural Event Type')\n",
    "        plt.savefig(dirs['causal_relationships'] / 'relationships_by_event_type.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"  ‚úì Saved 4 causal relationships visualizations\")\n",
    "\n",
    "def save_temporal_analysis_visualizations(neural_events_df, phoneme_annotations, causal_df, dirs):\n",
    "    \"\"\"Create and save temporal analysis visualizations\"\"\"\n",
    "    \n",
    "    print(\"‚è∞ Creating temporal analysis visualizations...\")\n",
    "    \n",
    "    # 1. Neural events and phonemes timeline\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot neural events\n",
    "    plt.subplot(3, 1, 1)\n",
    "    neural_timeline = neural_events_df.groupby(neural_events_df['timestamp'].round(1)).size()\n",
    "    plt.plot(neural_timeline.index, neural_timeline.values, label='Neural Events', alpha=0.7)\n",
    "    plt.title('Neural Events Timeline')\n",
    "    plt.ylabel('Event Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot phonemes\n",
    "    plt.subplot(3, 1, 2)\n",
    "    phoneme_timeline = phoneme_annotations.groupby(phoneme_annotations['start_time'].round(1)).size()\n",
    "    plt.plot(phoneme_timeline.index, phoneme_timeline.values, label='Phonemes', color='orange', alpha=0.7)\n",
    "    plt.title('Phoneme Timeline')\n",
    "    plt.ylabel('Phoneme Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot relationship density\n",
    "    plt.subplot(3, 1, 3)\n",
    "    # Calculate relationship density over time (simplified approach)\n",
    "    try:\n",
    "        # Create a simple time mapping for causal relationships\n",
    "        causal_times = []\n",
    "        for _, row in causal_df.iterrows():\n",
    "            # Use a sample of relationships to avoid memory issues\n",
    "            if len(causal_times) < 10000:  # Limit for performance\n",
    "                # Approximate time based on delay\n",
    "                approx_time = row['delay_ms'] / 1000.0  # Convert to seconds\n",
    "                causal_times.append(approx_time)\n",
    "        \n",
    "        if causal_times:\n",
    "            causal_series = pd.Series(causal_times)\n",
    "            relationship_timeline = causal_series.groupby(causal_series.round(1)).size()\n",
    "            plt.plot(relationship_timeline.index, relationship_timeline.values, \n",
    "                    label='Causal Relationships', color='green', alpha=0.7)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Skipping causal timeline due to: {e}\")\n",
    "        plt.plot([0, 1], [0, 0], label='Causal Relationships (unavailable)', color='green', alpha=0.7)\n",
    "    \n",
    "    plt.title('Causal Relationships Timeline')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Relationship Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['temporal_analysis'] / 'temporal_overview.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Delay patterns over time\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    try:\n",
    "        # Sample data for performance\n",
    "        sample_causal = causal_df.sample(min(10000, len(causal_df)))\n",
    "        time_bins = pd.cut(sample_causal['delay_ms'], bins=20)\n",
    "        delay_by_time = sample_causal.groupby(time_bins)['delay_ms'].mean()\n",
    "        \n",
    "        plt.plot(range(len(delay_by_time)), delay_by_time.values, marker='o')\n",
    "        plt.title('Average Causal Delay Distribution (Binned)')\n",
    "        plt.xlabel('Delay Bin')\n",
    "        plt.ylabel('Average Delay (ms)')\n",
    "        plt.xticks(range(0, len(delay_by_time), 2), rotation=45)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Simplified delay analysis due to: {e}\")\n",
    "        plt.hist(causal_df['delay_ms'].sample(min(10000, len(causal_df))), bins=20)\n",
    "        plt.title('Causal Delay Distribution (Sample)')\n",
    "        plt.xlabel('Delay (ms)')\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['temporal_analysis'] / 'delay_patterns_over_time.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  ‚úì Saved 2 temporal analysis visualizations\")\n",
    "\n",
    "def save_channel_analysis_visualizations(neural_events_df, causal_df, dirs):\n",
    "    \"\"\"Create and save channel analysis visualizations\"\"\"\n",
    "    \n",
    "    print(\"üì° Creating channel analysis visualizations...\")\n",
    "    \n",
    "    # 1. Channel activity overview\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    channel_counts = neural_events_df['channel'].value_counts().sort_index()\n",
    "    plt.bar(channel_counts.index, channel_counts.values)\n",
    "    plt.title('Neural Activity by Channel')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Number of Events')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['channel_analysis'] / 'channel_activity_overview.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Channel involvement in causal relationships\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    channel_relationships = causal_df['channel'].value_counts().sort_index()\n",
    "    plt.bar(channel_relationships.index, channel_relationships.values, color='orange')\n",
    "    plt.title('Channel Involvement in Causal Relationships')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Number of Relationships')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dirs['channel_analysis'] / 'channel_relationships.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Channel regions analysis (if available)\n",
    "    if 'channel_region' in neural_events_df.columns:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Region activity\n",
    "        plt.subplot(2, 1, 1)\n",
    "        region_activity = neural_events_df['channel_region'].value_counts().sort_index()\n",
    "        plt.bar(region_activity.index, region_activity.values)\n",
    "        plt.title('Neural Activity by Brain Region')\n",
    "        plt.xlabel('Region')\n",
    "        plt.ylabel('Number of Events')\n",
    "        \n",
    "        # Region relationship involvement\n",
    "        plt.subplot(2, 1, 2)\n",
    "        # Map channels to regions for causal_df\n",
    "        channel_to_region = neural_events_df.groupby('channel')['channel_region'].first()\n",
    "        causal_df['region'] = causal_df['channel'].map(channel_to_region)\n",
    "        region_relationships = causal_df['region'].value_counts().sort_index()\n",
    "        plt.bar(region_relationships.index, region_relationships.values, color='orange')\n",
    "        plt.title('Causal Relationships by Brain Region')\n",
    "        plt.xlabel('Region')\n",
    "        plt.ylabel('Number of Relationships')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dirs['channel_analysis'] / 'brain_region_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(f\"  ‚úì Saved 3 channel analysis visualizations\")\n",
    "\n",
    "def save_interactive_visualizations(neural_events_df, phoneme_annotations, causal_df, dirs):\n",
    "    \"\"\"Create and save interactive plotly visualizations\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Creating interactive visualizations...\")\n",
    "    \n",
    "    # 1. Interactive neural events timeline\n",
    "    fig = px.scatter(neural_events_df.sample(1000), x='timestamp', y='channel', \n",
    "                     color='event_type', hover_data=['amplitude'],\n",
    "                     title='Interactive Neural Events Timeline (Sample)')\n",
    "    fig.write_html(dirs['interactive'] / 'neural_events_timeline.html')\n",
    "    \n",
    "    # 2. Interactive phoneme frequency\n",
    "    phoneme_counts = phoneme_annotations['phoneme'].value_counts().head(20)\n",
    "    fig = px.bar(x=phoneme_counts.index, y=phoneme_counts.values,\n",
    "                 title='Interactive Phoneme Frequency Distribution')\n",
    "    fig.update_xaxes(title='Phoneme')\n",
    "    fig.update_yaxes(title='Frequency')\n",
    "    fig.write_html(dirs['interactive'] / 'phoneme_frequency.html')\n",
    "    \n",
    "    # 3. Interactive 3D scatter of causal relationships\n",
    "    sample_causal = causal_df.sample(min(5000, len(causal_df)))\n",
    "    fig = px.scatter_3d(sample_causal, x='delay_ms', y='strength', z='channel',\n",
    "                        color='phoneme', title='3D Causal Relationships (Sample)')\n",
    "    fig.write_html(dirs['interactive'] / 'causal_relationships_3d.html')\n",
    "    \n",
    "    # 4. Interactive heatmap\n",
    "    pivot_data = causal_df.groupby(['phoneme', 'channel']).size().reset_index(name='count')\n",
    "    top_phonemes = pivot_data.groupby('phoneme')['count'].sum().nlargest(10).index\n",
    "    top_channels = pivot_data.groupby('channel')['count'].sum().nlargest(20).index\n",
    "    \n",
    "    filtered_data = pivot_data[pivot_data['phoneme'].isin(top_phonemes) & \n",
    "                              pivot_data['channel'].isin(top_channels)]\n",
    "    \n",
    "    heatmap_matrix = filtered_data.pivot(index='phoneme', columns='channel', values='count').fillna(0)\n",
    "    \n",
    "    fig = px.imshow(heatmap_matrix, \n",
    "                    title='Interactive Phoneme-Channel Relationship Heatmap',\n",
    "                    color_continuous_scale='viridis')\n",
    "    fig.write_html(dirs['interactive'] / 'phoneme_channel_heatmap.html')\n",
    "    \n",
    "    print(f\"  ‚úì Saved 4 interactive visualizations\")\n",
    "\n",
    "def save_network_graph_visualizations(causal_df, phoneme_annotations, dirs):\n",
    "    \"\"\"Create and save network graph visualizations\"\"\"\n",
    "    \n",
    "    print(\"üï∏Ô∏è Creating network graph visualizations...\")\n",
    "    \n",
    "    # Sample data for network visualization (full dataset would be too large)\n",
    "    sample_size = min(1000, len(causal_df))\n",
    "    sample_causal = causal_df.sample(sample_size)\n",
    "    \n",
    "    # Create network graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for phonemes and neural events\n",
    "    for phoneme in sample_causal['phoneme'].unique():\n",
    "        G.add_node(f\"P_{phoneme}\", node_type='phoneme', label=phoneme)\n",
    "    \n",
    "    for channel in sample_causal['channel'].unique():\n",
    "        G.add_node(f\"C_{channel}\", node_type='channel', label=f\"Ch{channel}\")\n",
    "    \n",
    "    # Add edges for relationships\n",
    "    for _, row in sample_causal.iterrows():\n",
    "        G.add_edge(f\"P_{row['phoneme']}\", f\"C_{row['channel']}\", \n",
    "                   weight=row['strength'], delay=row['delay_ms'])\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "    \n",
    "    # Draw phoneme nodes\n",
    "    phoneme_nodes = [n for n in G.nodes() if n.startswith('P_')]\n",
    "    channel_nodes = [n for n in G.nodes() if n.startswith('C_')]\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=phoneme_nodes, node_color='lightblue', \n",
    "                          node_size=300, label='Phonemes')\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=channel_nodes, node_color='lightcoral', \n",
    "                          node_size=200, label='Channels')\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3, width=0.5)\n",
    "    \n",
    "    # Draw labels\n",
    "    labels = {node: G.nodes[node]['label'] for node in G.nodes()}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "    \n",
    "    plt.title('Neural-Phoneme Network Graph (Sample)', size=16)\n",
    "    plt.legend()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(dirs['network_graphs'] / 'neural_phoneme_network.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save network statistics\n",
    "    with open(dirs['network_graphs'] / 'network_stats.txt', 'w') as f:\n",
    "        f.write(f\"Network Statistics (Sample of {sample_size} relationships):\\n\")\n",
    "        f.write(f\"Nodes: {G.number_of_nodes()}\\n\")\n",
    "        f.write(f\"Edges: {G.number_of_edges()}\\n\")\n",
    "        f.write(f\"Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\\n\")\n",
    "        f.write(f\"Network density: {nx.density(G):.4f}\\n\")\n",
    "        \n",
    "        if nx.is_connected(G):\n",
    "            f.write(f\"Average path length: {nx.average_shortest_path_length(G):.2f}\\n\")\n",
    "            f.write(f\"Diameter: {nx.diameter(G)}\\n\")\n",
    "    \n",
    "    print(f\"  ‚úì Saved network graph and statistics\")\n",
    "\n",
    "def save_kumo_graph_visualizations(graph, dirs):\n",
    "    \"\"\"Save Kumo AI graph visualizations if possible\"\"\"\n",
    "    \n",
    "    print(\"üìä Creating Kumo graph visualizations...\")\n",
    "    \n",
    "    try:\n",
    "        # Try to save Kumo's built-in visualization\n",
    "        if hasattr(graph, 'visualize'):\n",
    "            # This might not work with all Kumo versions, but let's try\n",
    "            graph.visualize(save_path=str(dirs['kumo_graphs'] / 'kumo_schema.png'))\n",
    "            print(\"  ‚úì Saved Kumo schema visualization\")\n",
    "        else:\n",
    "            print(\"  ‚ö†Ô∏è Kumo visualization not available\")\n",
    "            \n",
    "        # Save graph summary\n",
    "        with open(dirs['kumo_graphs'] / 'kumo_graph_summary.txt', 'w') as f:\n",
    "            f.write(\"Kumo AI Graph Summary\\n\")\n",
    "            f.write(\"=\" * 30 + \"\\n\")\n",
    "            f.write(f\"Created: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            \n",
    "            if hasattr(graph, 'tables'):\n",
    "                f.write(\"Tables:\\n\")\n",
    "                for table_name in graph.tables.keys():\n",
    "                    f.write(f\"  - {table_name}\\n\")\n",
    "            \n",
    "            f.write(\"\\nGraph Configuration:\\n\")\n",
    "            f.write(\"  - Temporal columns configured\\n\")\n",
    "            f.write(\"  - Primary keys set\\n\")\n",
    "            f.write(\"  - Edge relationships defined\\n\")\n",
    "        \n",
    "        print(\"  ‚úì Saved Kumo graph summary\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not save Kumo visualizations: {e}\")\n",
    "\n",
    "def create_summary_report(neural_events_df, phoneme_annotations, causal_df, dirs):\n",
    "    \"\"\"Create a comprehensive summary report\"\"\"\n",
    "    \n",
    "    print(\"üìã Creating summary report...\")\n",
    "    \n",
    "    # Create HTML summary report\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Neural-Phoneme Analysis Summary</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "            .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 10px; }}\n",
    "            .section {{ margin: 20px 0; }}\n",
    "            .stat {{ background-color: #e8f4f8; padding: 10px; margin: 5px 0; border-radius: 5px; }}\n",
    "            .visualization-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}\n",
    "            .viz-card {{ border: 1px solid #ddd; padding: 15px; border-radius: 10px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>üß† Neural-Phoneme BCI Analysis Summary</h1>\n",
    "            <p>Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>üìä Dataset Overview</h2>\n",
    "            <div class=\"stat\">Neural Events: {len(neural_events_df):,}</div>\n",
    "            <div class=\"stat\">Phoneme Annotations: {len(phoneme_annotations):,}</div>\n",
    "            <div class=\"stat\">Causal Relationships: {len(causal_df):,}</div>\n",
    "            <div class=\"stat\">Unique Channels: {neural_events_df['channel'].nunique()}</div>\n",
    "            <div class=\"stat\">Unique Phonemes: {phoneme_annotations['phoneme'].nunique()}</div>\n",
    "            <div class=\"stat\">Sparsity: {(len(causal_df) / (len(neural_events_df) * len(phoneme_annotations))) * 100:.2f}%</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>‚è∞ Temporal Statistics</h2>\n",
    "            <div class=\"stat\">Neural Recording Duration: {neural_events_df['timestamp'].max() - neural_events_df['timestamp'].min():.2f} seconds</div>\n",
    "            <div class=\"stat\">Average Causal Delay: {causal_df['delay_ms'].mean():.1f} ¬± {causal_df['delay_ms'].std():.1f} ms</div>\n",
    "            <div class=\"stat\">Delay Range: {causal_df['delay_ms'].min():.1f} - {causal_df['delay_ms'].max():.1f} ms</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>üéØ Key Findings</h2>\n",
    "            <div class=\"stat\">Most Active Channel: {neural_events_df['channel'].value_counts().index[0]} ({neural_events_df['channel'].value_counts().iloc[0]:,} events)</div>\n",
    "            <div class=\"stat\">Most Common Phoneme: {phoneme_annotations['phoneme'].value_counts().index[0]} ({phoneme_annotations['phoneme'].value_counts().iloc[0]:,} occurrences)</div>\n",
    "            <div class=\"stat\">Peak Relationship Strength: {causal_df['strength'].max():.3f}</div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>üìÅ Visualization Categories</h2>\n",
    "            <div class=\"visualization-grid\">\n",
    "                <div class=\"viz-card\">\n",
    "                    <h3>üß† Neural Events</h3>\n",
    "                    <p>Event distributions, timeline analysis, amplitude patterns</p>\n",
    "                </div>\n",
    "                <div class=\"viz-card\">\n",
    "                    <h3>üó£Ô∏è Phoneme Analysis</h3>\n",
    "                    <p>Frequency distributions, duration analysis, sequence patterns</p>\n",
    "                </div>\n",
    "                <div class=\"viz-card\">\n",
    "                    <h3>üîó Causal Relationships</h3>\n",
    "                    <p>Delay distributions, strength analysis, phoneme-channel mappings</p>\n",
    "                </div>\n",
    "                <div class=\"viz-card\">\n",
    "                    <h3>‚è∞ Temporal Analysis</h3>\n",
    "                    <p>Timeline correlations, delay patterns, temporal dynamics</p>\n",
    "                </div>\n",
    "                <div class=\"viz-card\">\n",
    "                    <h3>üì° Channel Analysis</h3>\n",
    "                    <p>Channel activity, brain region analysis, spatial patterns</p>\n",
    "                </div>\n",
    "                <div class=\"viz-card\">\n",
    "                    <h3>üîÑ Interactive</h3>\n",
    "                    <p>Plotly visualizations, 3D scatter plots, interactive heatmaps</p>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(dirs['summary_reports'] / 'analysis_summary.html', 'w') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    # Create text summary\n",
    "    with open(dirs['summary_reports'] / 'analysis_summary.txt', 'w') as f:\n",
    "        f.write(\"NEURAL-PHONEME BCI ANALYSIS SUMMARY\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"DATASET OVERVIEW:\\n\")\n",
    "        f.write(f\"  Neural Events: {len(neural_events_df):,}\\n\")\n",
    "        f.write(f\"  Phoneme Annotations: {len(phoneme_annotations):,}\\n\")\n",
    "        f.write(f\"  Causal Relationships: {len(causal_df):,}\\n\")\n",
    "        f.write(f\"  Unique Channels: {neural_events_df['channel'].nunique()}\\n\")\n",
    "        f.write(f\"  Unique Phonemes: {phoneme_annotations['phoneme'].nunique()}\\n\")\n",
    "        f.write(f\"  Sparsity: {(len(causal_df) / (len(neural_events_df) * len(phoneme_annotations))) * 100:.2f}%\\n\\n\")\n",
    "        \n",
    "        f.write(\"KEY STATISTICS:\\n\")\n",
    "        f.write(f\"  Average Causal Delay: {causal_df['delay_ms'].mean():.1f} ¬± {causal_df['delay_ms'].std():.1f} ms\\n\")\n",
    "        f.write(f\"  Most Active Channel: {neural_events_df['channel'].value_counts().index[0]}\\n\")\n",
    "        f.write(f\"  Most Common Phoneme: {phoneme_annotations['phoneme'].value_counts().index[0]}\\n\")\n",
    "        f.write(f\"  Peak Relationship Strength: {causal_df['strength'].max():.3f}\\n\")\n",
    "    \n",
    "    print(\"  ‚úì Saved HTML and text summary reports\")\n",
    "\n",
    "def main_visualization_pipeline(neural_events_df, phoneme_annotations, causal_df, graph=None):\n",
    "    \"\"\"Main function to execute the complete visualization pipeline\"\"\"\n",
    "    \n",
    "    print(\"üé® STARTING COMPREHENSIVE VISUALIZATION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Setup directories\n",
    "    dirs = setup_visualization_directories()\n",
    "    \n",
    "    # Create all visualizations\n",
    "    save_neural_events_visualizations(neural_events_df, dirs)\n",
    "    save_phoneme_analysis_visualizations(phoneme_annotations, dirs)\n",
    "    save_causal_relationships_visualizations(causal_df, dirs)\n",
    "    save_temporal_analysis_visualizations(neural_events_df, phoneme_annotations, causal_df, dirs)\n",
    "    save_channel_analysis_visualizations(neural_events_df, causal_df, dirs)\n",
    "    save_interactive_visualizations(neural_events_df, phoneme_annotations, causal_df, dirs)\n",
    "    save_network_graph_visualizations(causal_df, phoneme_annotations, dirs)\n",
    "    \n",
    "    # Save Kumo graph visualizations if available\n",
    "    if graph is not None:\n",
    "        save_kumo_graph_visualizations(graph, dirs)\n",
    "    \n",
    "    # Create summary report\n",
    "    create_summary_report(neural_events_df, phoneme_annotations, causal_df, dirs)\n",
    "    \n",
    "    print(\"\\nüéâ VISUALIZATION PIPELINE COMPLETE!\")\n",
    "    print(f\"üìÅ All visualizations saved to: {dirs['base']}\")\n",
    "    print(f\"üìã Summary report: {dirs['summary_reports'] / 'analysis_summary.html'}\")\n",
    "    \n",
    "    return dirs\n",
    "\n",
    "# Usage instructions\n",
    "def show_usage():\n",
    "    \"\"\"Show usage instructions\"\"\"\n",
    "    \n",
    "    print(\"\\nüìñ USAGE INSTRUCTIONS:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(\"1. Make sure you have the required packages:\")\n",
    "    print(\"   pip install matplotlib seaborn plotly networkx\")\n",
    "    print()\n",
    "    print(\"2. Run the visualization pipeline:\")\n",
    "    print(\"   dirs = main_visualization_pipeline(neural_events_df, phoneme_annotations, causal_df, graph)\")\n",
    "    print()\n",
    "    print(\"3. View your visualizations in the graphs/ directory\")\n",
    "    print(\"4. Open graphs/summary_reports/analysis_summary.html in a browser\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_usage()\n",
    "    \n",
    "    # Check if required data is available\n",
    "    required_vars = ['neural_events_df', 'phoneme_annotations', 'causal_df']\n",
    "    if all(var in globals() for var in required_vars):\n",
    "        print(\"\\n‚úÖ Found all required data - running visualization pipeline...\")\n",
    "        graph = globals().get('comprehensive_results', {}).get('graph', None)\n",
    "        dirs = main_visualization_pipeline(neural_events_df, phoneme_annotations, causal_df, graph)\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è Missing data - make sure you have: {required_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5bc1811-8cbe-4ded-8b4f-0cd59b341a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (6.3.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/lib/python3/dist-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/lib/python3/dist-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from plotly) (21.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.local/lib/python3.10/site-packages (from plotly) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn matplotlib plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3bdf0-07ba-4dd8-b667-3519d62454ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
